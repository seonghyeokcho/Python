{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSD: Single Shot Multibox Detection\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview\n",
    "- 지도학습의 한 종류이기 때문에 이미지 안에 정답 경계상자, 클래스 정보가 담긴 `정답 이미지`가 존재해야 하며,<br>\n",
    "알고리즘이 `정답 경계상자`를 찾고, 각 `정답 경계상자`에 속한 객체를 예측해야 함\n",
    "    - `정답 경계상자`: Ground Truth Bounding box, `GTBB`\n",
    "- 이미지마다 존재하는 객체의 수, 객체의 위치, 객체의 크기, 객체의 형태가 다르다. 그러므로<br>\n",
    "아무것도 없는 상태의 이미지에서 위치, 크기, 형태가 각각 다른 `GTBB`를 예측하는 것은 어렵기 때문에<br>\n",
    "`기본상자`라는 것을 사용\n",
    "    - `기본상자`: Anchor box or Default box\n",
    "- Default box(기본상자)\n",
    "    - 다양한 위치, 크기, 형태의 default boxes를 사용하여 default boxes를 기준점으로 GTBB가 default boxes로부터<br>\n",
    "    얼마나 떨어져 있는지(`offset` 정도), 그리고 해당 GTBB에 존재하는 객체가 무엇인지를 예측함(두 작업 동시 수행)\n",
    "        - bounding box regression: `offset` 정도 예측, Classification: 물체(객체)의 `클래스 분류`\n",
    "    - SSD는 default boxes를 원본 이미지에서 설정하지 않고 `사전학습모형(VGG-16)`과 `추가적인 합성곱 레이어`를 이용하여<br>\n",
    "    특징 맵(feature map)을 추출하고, 추출된 특징 맵(feature map)에서 default boxes를 설정하여 사용함\n",
    "        - `사전 학습 모형`: backbone network라고 일컬음\n",
    "- Feature map(특징 맵)\n",
    "    - SSD는 Object Detection을 위해 사용하는 `특징 맵의 수가 6개`\n",
    "        - 1차적으로 VGG-16과 같은 `사전학습모형(backbone network)`을 사용하여 `6개`의 특징 맵을 추출하고,<br>\n",
    "        그 중 마지막 `6번째 특징 맵`을 사용(Conv4_3)\n",
    "        - `추가적인 합성곱 레이어`를 사용하여 다시 `6개`의 특징 맵을 추출하고, 그 중 `5개`를 사용\n",
    "        - 결론적으로 `사전학습모형(1개) + 합성곱 레이어(5개) = 6개의 크기가 각각 다른 특징 맵`을 사용하고,<br>\n",
    "        이를 이용하여 물체(객체)를 탐지하여 다양한 크기의 물체(객체)를 잘 찾을 수 있음(`multi-scale object detection`)\n",
    "            - `multi-scale object detection`은 SSD의 가장 큰 장점 중 하나\n",
    "    - <img src=\"../markdown/SSD_architecture.png\" width=\"800\">\n",
    "<hr>\n",
    "\n",
    "- Feature map에 Default boxes 설정<br>\n",
    "<br>\n",
    "    - 하나의 특징 맵은 격자판(grid)하고 생각할 수 있음\n",
    "        - 격자판(grid)에는 격자판(grid) 크기 만큼의 `cell`이 존재함\n",
    "            - e.g., 25 cells exists in 5x5 grid(5x5=25)\n",
    "    - 각 feature map은 output으로 연결되는 또하나의 convolution layer를 거쳐 각각의 `cell`에 대하여<br>\n",
    "    `4개 or 6개`의 default boxes를 설정하고, 그에 `대응`하는 `cell`의 순서 & `해당` default box에서 `GTBB`의<br>\n",
    "    `offset(cx, cy, w, h)`과 `GTBB`안에 존재하는 물체의 `confidences`값을 예측함\n",
    "        - SSD는 총 21개(`background 1 + object class 20`)의 클래스를 사용하기 때문에 `confidences=21`이 됨\n",
    "        - 이 때 사용하는 convolution layer는 filter=3 x 3 x (k x (classes+4)), padding=1, stride=1\n",
    "            - `k`: 4 or 6\n",
    "        - 위 SSD 구조 이미지에서 `Conv4_3[1], Conv10_2[5], Conv11_2[6]`에서는 `cell 당 4개`의 default boxes를,<br>\n",
    "        `Conv7[2], Conv8_2[3], Conv9_2[4]`에서는 `cell 당 6개`의 default boxes를 설정함\n",
    "            - result of Conv4_3: 38 x 38 x (`4` x (classes + 4)), `5776` x (classes + 4)\n",
    "            - result of Conv7: 19 x 19 x (`6` x (classes + 4)), `2166` x (classes + 4)\n",
    "            - result of Conv8_2: 10 x 10 x (`6` x (classes + 4)), `600` x (classes + 4)\n",
    "            - result of Conv9_2: 5 x 5 x (`6` x (classes + 4)), `125` x (classes + 4)\n",
    "            - result of Conv10_2: 3 x 3 x (`4` x (classes + 4)), `36` x (classes + 4)\n",
    "            - result of Conv11_2: 1 x 1 x (`4` x (classes + 4)), `4` x (classes + 4)\n",
    "            - 클래스 당 `8732`개의 default boxes 설정 & 그에 대응하는 각각의 default box 자리에서<br>\n",
    "            정답을 예측(detect)함\n",
    "                - 이후 모델은 `비최대 억제(Non-maximum Suppression)` 과정을 거쳐 `confidence`값이 가장 높은<br>\n",
    "                `bounding box`를 `test output(결과)`을 내보냄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Choosing scales and aspect ratio for default boxes(기본 상자를 설정하기 위한 규모와 종횡비 선택)<br>\n",
    "<br>\n",
    "    - 각 셀에 대한 default boxes의 설정 방법\n",
    "        - 보다 다양한 형태의 물체를 찾기 위해 다양한 형태의 default boxes를 사용하며, default boxes의 형태는<br>\n",
    "        `scaling factor`와 `aspect ratio`에 의해 결점됨\n",
    "        - Scaling factor\n",
    "            - default boxes의 `상대적인 크기`를 결정\n",
    "            - k번째 feature map에 대한 scaling factor는 아래와 같이 계산됨\n",
    "                - $S_k = S_{min} + \\frac{S_{max}-S_{min}}{m-1}(k-1),\\quad k\\in [1, m]$\n",
    "                - $S_{min} = 0.2,\\ S_{max} = 0.9$\n",
    "                - $m$은 feature map의 개수를 의미하며 SSD는 총 `6개의 feature map`을<br>\n",
    "                사용하기 때문에 $m$의 최댓값은 `6`\n",
    "                    - $k=1$, $S_k$ = 0.2 $(S_{min})$\n",
    "                    - $k=2$, $S_k$ = 0.34\n",
    "                    - $k=3$, $S_k$ = 0.48\n",
    "                    - $k=4$, $S_k$ = 0.62\n",
    "                    - $k=5$, $S_k$ = 0.76\n",
    "                    - $k=6$, $S_k$ = 0.9 $(S_{max})$\n",
    "        - Aspect ratio\n",
    "            - default boxes의 `가로세로 비율(종횡비)`을 결정\n",
    "            - cell당 default boxes가 `4개`인 경우\n",
    "                - $a_r\\in \\{1,2,\\frac{1}{2}\\}$ -> `3개` + `extra 1개`\n",
    "            - cell당 default boxes가 `6개`인 경우\n",
    "                - $a_r\\in\\{1,2,3,\\frac{1}{2},\\frac{1}{3}\\}$ -> `5개` + `extra 1개`\n",
    "            - `extra scaling factor` $S'_k$를 사용하여 $a_r=1$ 인 default box보다 조금 더 큰 사이즈의<br>\n",
    "            default box를 추가로 사용함\n",
    "                - $S'_k = \\sqrt {S_k S_{k+1}}$\n",
    "        - `k번째` Feature map(grid)에 대해 `1개 cell`에 존재하는 `default boxes`의 크기(w, h)는<br>\n",
    "        아래와 같이 결정됨\n",
    "            - $(w^a_k,\\ h^a_k)=(S_k\\sqrt{a_r},\\ S_k\\frac{1}{\\sqrt{a_r}})$\n",
    "            - $(w^a_k,\\ h^a_k)=(S'_k,\\ S'_k),\\quad\\mathsf{where}\\ \\ S'_k=\\sqrt{S_k S_{k+1}}$\n",
    "            - $w^a_k,\\ h^a_k$ = `k번째` feature map(grid)의 `a(종횡비)`가 적용된 default boxes의 `너비와 높이`\n",
    "            - $S_k$ = `k번째` feature map의 `scaling factor`\n",
    "            - $a_r$ = default boxes의 `aspect ratio(종횡비)`\n",
    "            - $S'_k$ = 추가적인 `scaling factor`\n",
    "        - Default box 가로세로 크기의 모든 경우의 수\n",
    "            - $k=1$일 때\n",
    "                - (0.2, 0.2)\n",
    "                - (0.28, 0.14)\n",
    "                - (0.35, 0.12)\n",
    "                - (0.14, 0.28)\n",
    "                - (0.12, 0.35)\n",
    "                - (0.26, 0.26)\n",
    "            - $k=2$일 때\n",
    "                - (0.34, 0.34)\n",
    "                - (0.48, 0.24)\n",
    "                - (0.59, 0.2)\n",
    "                - (0.24, 0.48)\n",
    "                - (0.2, 0.59)\n",
    "                - (0.4, 0.4)\n",
    "            - $k=3$일 때\n",
    "                - (0.48, 0.48)\n",
    "                - (0.68, 0.34)\n",
    "                - (0.83, 0.28)\n",
    "                - (0.34, 0.68)\n",
    "                - (0.28, 0.83)\n",
    "                - (0.55, 0.55)\n",
    "            - $k=4$일 때\n",
    "                - (0.62, 0.62)\n",
    "                - (0.88, 0.44)\n",
    "                - (1.07, 0.36)\n",
    "                - (0.44, 0.88)\n",
    "                - (0.36, 1.07)\n",
    "                - (0.69, 0.69)\n",
    "            - $k=5$일 때\n",
    "                - (0.76, 0.76)\n",
    "                - (1.07, 0.54)\n",
    "                - (1.32, 0.44)\n",
    "                - (0.54, 1.07)\n",
    "                - (0.44, 1.32)\n",
    "                - (0.83, 0.83)\n",
    "            - $k=6$일 때\n",
    "                - (0.9, 0.9)\n",
    "                - (1.27, 0.64)\n",
    "                - (1.56, 0.52)\n",
    "                - (0.64, 1.27)\n",
    "                - (0.52, 1.56)\n",
    "                - `(0.97, 0.97)`-> `k가 7`이어야 계산이 가능하기 때문에 존재하지 않음(?)\n",
    "        - 각 cell마다 default boxes가 위치할 `중심점(cx, cy)` 설정\n",
    "            - 각각의 `cell`마다 `4개` or `6개`의 default boxes가 위치하려면 `해당 cell의 중심점`이 필요하며,<br>\n",
    "            그 `중심점`은 아래와 같이 계산됨\n",
    "            - $(\\frac{i+0.5}{|f_{k}|},\\ \\frac{j+0.5}{|f_{k}|}),\\quad{\\scriptstyle\\text{where }}|f_{k}|={\\scriptstyle\\text{k번째 square feature map의 한 변의 길이}},\\quad i,j\\in[0,|f_{k}|)$\n",
    "        - 정리하자면 특징 맵의 순서 k가 [1,6]일 때, 각 특징맵에 존재하는 m x n 만큼의 cells 에서 1개의 cell에 설정되는<br>\n",
    "        default boxes는 특징 맵의 순서에 따라 4개 or 6개가 설정되고, 각 default box의 (cx, cy, w, h)는<br>\n",
    "        $(\\frac{i+0.5}{|f_{k}|},\\ \\frac{j+0.5}{|f_{k}|},\\ w^a_k,\\ h^a_k)$으로 정해짐\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Matching strategy(매칭 전략)<br>\n",
    "<br>\n",
    "    - 훈련이 진행되는 동안 어떠한 `default box`가 `정답을 탐지`한 것에 해당하는지 결정하고 그에 따라서 모델을 훈련 시켜야 함\n",
    "        - 각 `default box`는 `(cx, cy, w, h)`값을 가지고 있고, 해당 값을 이용하여 `ground truth box`와 겹치는 정도를<br>\n",
    "        계산하기 위해 `Jaccard overlap` 지표를 사용함\n",
    "            - `Jaccard overlap`: object detector의 성능 평가 지표로 사용되고,<br>\n",
    "            `Intersection over Union(IoU)`라고도 칭하며, `0~1` 사이의 실수값을 가짐\n",
    "            - <img src=\"../markdown/intersection_over_union.png\" width=\"400\">\n",
    "        - 먼저 각 `ground truth box`에 대하여 `IoU값`이 가장 큰 `default box`를 찾고, 해당 `ground truth box`와 매칭함(`ground truth box`는 1개 이상)\n",
    "        - 이후 `ground truth box`를 할당 받지 못 한 `default boxes` 중 `IoU값`이 `0.5`보다 큰 `default boxes` 또한<br>\n",
    "        해당 `ground truth box`와 매칭함\n",
    "            - 만약 임의의 `default box`에서 `IoU값`이 `0.5`보다 큰 `ground truth box`가 2개 이상 존재한다면 그 중 가장 큰<br>\n",
    "            `IoU값`을 갖는 `ground truth box`와 매칭함\n",
    "        - 이러한 매칭 전략은 각 특징 맵에서 `maximum overlap`이 발생하는 것만 선택하도록 요구하는 방향으로 학습되는<br>\n",
    "        대신에 여러 `overlapping default boxes`에 대해 네트워크가 `좋은 성능을 발휘`할 수 있게 함\n",
    "        - 매칭 작업이 모두 끝난 `default boxes`는 `positives` = 매칭된 `default boxes`,<br>\n",
    "        `negatives` = 매칭되지 않은 `default boxes`로 분류됨\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training objective(훈련 목표)<br>\n",
    "<br>\n",
    "    - 네트워크는 두 가지의 값을 학습하기 위해 `손실함수(loss function)`를 계산함\n",
    "        - 먼저 $x_{ij}^p=\\{1,0\\}$ 를 `i`번째 default box와 클래스가 `p`인 `j`번째 ground truth box와 매칭되는<br>\n",
    "        지표로써 정의하고, 위의 `매칭 전략`에 따라 $\\sum_i x_{ij}^p \\ge 1$의 값을 가질 수 있음(`positives`가 적어도 1개 이상)\n",
    "        - `localization loss`는 `매칭`된 `i`번째 `default box(d)`와 같은 순번인 `i`번째 `predicted box(l)`를 고려함<br>\n",
    "        <br>\n",
    "            - $\\quad\\quad L_{loc}(x,l,g)=\\sum_{i\\in Pos}^N\\sum_{m\\in\\{cx,cy,w,h\\}} x_{ij}^k\\mathsf{smooth_{L1}}(l_i^m - \\hat g_j^m)$<br>\n",
    "            <br>\n",
    "            - $l=\\mathsf{{\\color{blue}predicted\\ box}}$\n",
    "            - $g=\\mathsf{ground\\ truth\\ box}$\n",
    "            - $\\hat g_j^{cx}=(g_j^{cx}-d_i^{cx})/d_i^w\\quad\\hat g_j^{cy}=(g_j^{cy}-d_i^{cy})/d_i^h$\n",
    "            - $\\hat g_j^{w}=log(\\frac{g_j^w}{d_i^w})\\quad\\hat g_j^{h}=log(\\frac{g_j^h}{d_i^h})$\n",
    "            - 위 식을 해석하자면 `positives` 중 $x_{ij}^k=1$인 `default box`와 같은 위치의 `predicted box`와<br>\n",
    "            클래스가 `k`인 `ground truth box`의 `offset loss(불일치 오차)`을 계산함\n",
    "                - 초기 예측값은 default box 위치와 같은 값을 예측하는 것으로 시작할 것이라고 예상됨<br>\n",
    "                <br>\n",
    "        - `confidence loss`는 `positives`와 `negatives` 둘다 사용하며 `positives`에 대해서는 다중 클래스에 대한<br>\n",
    "        `softmax loss`를, `negatives`에 대해서는 `background` 클래스에 대한 `confidence`값을 고려함<br>\n",
    "        <br>\n",
    "            - $\\quad\\quad L_{conf}(x,c)=-\\sum_{i\\in Pos}^N x_{ij}^p log(\\hat c_i^p)-\\sum_{i\\in Neg}log(\\hat c_i^0)\\quad\\mathsf{where}\\quad\\hat c_i^p=\\frac{exp(c_i^p)}{\\sum_p exp(c_i^p)}$<br>\n",
    "            <br>\n",
    "            - $\\hat c_i^p=$ 다중 클래스에 대한 p 클래스의 `softmax loss`\n",
    "            - $\\hat c_i^0=\\frac{exp(c_i^0)}{\\sum_p exp(c_i^0)}$ 다중 클래스에 대한 0 클래스의 `softmax loss`\n",
    "            - 위 식 또한 해석해보자면 `positives` 중 $x_{ij}^p=1$인 `default box`와 같은 위치의 `predicted box`와<br>\n",
    "            클래스가 `p`인 `ground truth box`의 `confidence loss(신뢰도 오차)`를 계산하고, `negatives` 또한 같은 방법으로 계산하여 마지막으로 더해줌<br>\n",
    "            <br>\n",
    "        - 전체적인 `objective loss function`은 위 두가지 `loss`값의 `가중합(weighted sum)`으로 구성됨<br>\n",
    "        <br>\n",
    "            - $\\quad\\quad L(x,c,l,g)=\\frac{1}{N}(L_{conf}(x,c)+\\alpha L_{loc}(x,l,g))$<br>\n",
    "            <br>\n",
    "            - $N=$ 매칭 지표$(x_{ij}^p)$에 의해 매칭된 default box의 수\n",
    "            - $\\alpha=$ 교차검증에 의해 얻어진 `1`로 설정함\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hard negative mining<br>\n",
    "<br>\n",
    "    - 매칭 단계 이후, 대부분의 `default box`는 `negatives`이고, 특히 가용 `default box`가 많을 경우엔<br>\n",
    "    이 비율이 더욱 커지며, 이는 positive와 negative 훈련 샘플 간에 심각한 `불균형(imbalance)`을 초래함\n",
    "    - 모든 `negatives`를 쓰는 것 대신에 각 default box에 대해 $L_{conf}$(`confidence loss`)값이 `높은` 것을 사용하여<br>\n",
    "    정렬하고, 그 중 가장 위부터 선별(선택)하여 $L_{conf}$(`confidence loss`)를 계산할 때 `negatives`와 `positives`의<br>\n",
    "    비율이 `최대 3:1`이 되도록 함\n",
    "        - 논문에서 저자들은 이러한 방법이 더 빠른 최적화와 더 안정적인 훈련으로 이어진다는 것을 발견했다고 서술함\n",
    "        - Hard negative mining 기법은 R-CNN, OHEM 등 다른 알고리즘에서도 사용되었음\n",
    "        - Hard negative mining은 모델이 예측에 실패하는 어려운(hard) sample들을 모으는 기법으로,<br>\n",
    "        Hard negative mining을 통해 수집된 데이터를 활용하여 모델을 보다 강건하게 학습시키는 것이 가능해짐\n",
    "            - 예를 들어 이미지에서 사람의 안면의 위치를 탐지하는 모델을 학습시킨다고 할 때, 사람의 안면은<br>\n",
    "            `positive sample`이며, 그외의 배경은 `negative sample`. 이 때 모델이 배경이라고 예측했으며,<br>\n",
    "            실제로 배경인 bounding box는 `True Negative sample`에 해당함. 반면에 모델이 안면이라고 예측했지만,<br>\n",
    "            실제로 배경인 경우는 `False Positive sample`에 해당함. 모델은 주로 `False Positive`라고 예측하는<br>\n",
    "            오류를 주로 범함. 이는 객체 탐지 시, 객체의 위치에 해당하는 `positive sample`보다 배경에 해당하는<br>\n",
    "            `negative sample`이 훨씬 많은 `클래스 불균형(class imbalance)`으로 인해 발생하게 됨.<br>\n",
    "            이러한 문제를 해결하기 위해 모델이 잘못 판단한 `False Positive sample`을 학습 과정에서 추가하여<br>\n",
    "            재학습하면 모델은 보다 강건해지며, `False Positive`라고 판단하는 오류가 줄어들게 됨\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- inference(추론)<br>\n",
    "<br>\n",
    "    - SSD는 추론하는 동안 `Non-maximum suppression(비최대억제)` 과정을 거치게 됨\n",
    "    - SSD는 출력으로 총 `[B, 8732, (classes + offset)]`의 default boxes와 predicted boxes를<br>\n",
    "    얻게 되는데 모두 사용하지 않고 `confidence threshold = 0.01` 이상의 boxes만을 사용하고,<br>\n",
    "    이 방법으로 대부분의 boxes가 필터링됨\n",
    "    - 이후 가장 높은 `confidence`값을 가진 `predicted box`를 최종 output으로 선정하면 좋겠지만,<br>\n",
    "    `IoU = 0.5` 이상인 `predicted box`가 여러개일 수 있고, 또한 이렇게되면 하나의 객체에 여러개의<br>\n",
    "    bounding box를 출력으로 내보내는 현상이 발생함.    \n",
    "        - 이를 방지하기 위해 `nms`과정으로 가장 높은 `confidence`값을 가진 `predicted box`를 기준으로<br>\n",
    "        `IoU`를 계산하여 `0.45` 이상의 값을 가지는 `predicted boxes`를 모두 제거한 후에 최종<br>\n",
    "        output으로 내보냄\n",
    "        - 위 과정들은 이미지안에 객체가 `1개`만 존재할 떄의 예시이고, 만약 이미지안에 객체가 `두개 이상`이라면<br>\n",
    "        각각의 객체마다 위 과정들이 적용됨\n",
    "        - 가장 높은 `confidence`값을 가진 `predicted box`와의 `IoU = 0.45` 이상이라는 것의 의미는<br>\n",
    "        같은 객체를 탐지하긴 했는데 `confidence` 값이 더 낮고, 겹치는 상자라는 의미이기 때문에<br>\n",
    "        `IoU = 0.45` 이하인 `predicted boxes`를 다른 객체를 탐지한 것이라고 판단하는 것임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R = FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38cc0cca68228d4d18227abe74ed813685db17db46984279e4aabdddebf5f1ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
