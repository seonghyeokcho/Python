{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection(객체 탐지)\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이미지 내에서 `객체(물체)`를 인식하는 방법<br>\n",
    "<br>\n",
    "    1. classification: `분류`라고 불리는 전통적인 방법은 하나의 이미지를 입력으로 받아서<br>\n",
    "    해당 이미지가 어떠한 `class`의 이미지인지 `구분`(예측하는) 것<br>\n",
    "<br>\n",
    "    2. localization: 지역화, 국소화라는 뜻을 가진 이 방법은 말그대로 객체가 있을만한 곳을<br>\n",
    "    `bounding box`라고 하는 것을 통해 `위치`를 찾는(예측하는) 것\n",
    "        - 위 1,2번은 공통적으로 하나의 이미지에 하나의 객체에 대해서 작업을 수행함<br>\n",
    "<br>\n",
    "    3. object detection: 위 1,2번이 합쳐진 형태로, 객체의 `위치와 클래스`를 함께 찾는 두 가지의 작업을 수행하는 것\n",
    "        - 위 1,2번과 다른점은 1,2번은 하나의 이미지에 `단일 객체`에 대한 작업이고, `객체 탐지(object detection)`는<br>\n",
    "        `다수의 객체`에 대한 작업<br>\n",
    "<br>\n",
    "    4. instance segmentation: 이미지 내에 각 객체를 `픽셀 단위`로 예측하는 작업을 수행하는<br>\n",
    "    형태로, `object detection`에서 조금 더 발전된 형태의 작업을 수행하는 것\n",
    "        - 추가적으로 sementic segmentation과 차이점은 `군집화(clustering)`이냐 `개별적(individually)`이냐의 차이<br>\n",
    "<br>\n",
    "- 객체 탐지의 `두 가지 작업(Task)`에 대한 세부사항<br>\n",
    "<br>\n",
    "    - localization(위치결정): 이미지 안에 존재하는 객체의 `위치 정보`를 `경계상자(bounding box)`를 통해 찾는 것\n",
    "        - `위치 정보`: 더 정확하게는 객체가 있을 것 같은 경계상자의 `offset`을 찾는 것<br>\n",
    "        `i.e., bounding box regression`<br>\n",
    "<br>\n",
    "    - Classification(분류): 해당 경계상자에 포함되어 있는 객체가 무엇인지 분류하는 것<br>\n",
    "<br>\n",
    "- 객체 탐지 알고리즘(Algorithm)의 종류\n",
    "    - `One Stage Detector(or Algorithm)`\n",
    "        - 위 두 작업을 한 번에 수행\n",
    "        - 알고리즘: SSD(Single Shot Detection), YOLO(You Only Look Once) 등\n",
    "        - 특징: `two stage detectors`에 비해 상대적으로 연산 속도가 빠르고, 정확도는 낮음\n",
    "    - `Two Stage Detector(or Algorithm)`\n",
    "        - 위 두 작업을 구분하여 수행\n",
    "        - 알고리즘: `R-CNN` family(R-CNN, Fast R-CNN, Faster R-CNN, `Mask R-CNN`)\n",
    "            - `R-CNN`: Region-based Convolutional Neural Network(영역 기반 합성곱 신경망)\n",
    "            - `Mask R-CNN`: 객체(물체) 탐지도 수행하지만 주 목적은 Object Detection보다<br>\n",
    "            발전된 형태인 픽셀 단위 Object Detection 즉, `Image Instance Segmentation`(이미지 분할)\n",
    "        - 특징: `one stage detectors`에 비해 상대적으로 연산 속도가 느리고, 정확도는 높음\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Region proposal(영역 제안)<br>\n",
    "<br>\n",
    "    - 물체가 있을 법한 위치(영역)를 찾는 과정을 뜻하며, 이러한 영역을 `관심 영역(Region of interest, ROI)`이라고 함<br>\n",
    "<br>\n",
    "    - 영역 제안 방법\n",
    "        1. `Sliding Window`\n",
    "            - 이미지내에서 다양한 형태의 `윈도우(window)` 혹은 `커널(kernel)`이 이미지 전체를 슬라이딩하며 물체가<br>\n",
    "            존재하는지 확인함\n",
    "            - 다만 너무 많은 영역에 대하여 확인해야 한다는 단점이 존재함. 특히 특징 맵이 아니라 입력 이미지 자체에 대해서<br>\n",
    "            `CPU`장치를 이용해 슬라이딩을 진행하게 되면 넓은 입력 공간(input space)상에서 많은 영역에 대하여 확인해야<br>\n",
    "            하므로 속도가 느릴수 있음\n",
    "            - 반례로 `Faster R-CNN(NIPS 2015)`에서는 `CPU`가 아닌 `GPU`에서 이 작업을 수행하도록 작성되어<br>\n",
    "            속도 측면에서 비약적인 발전을 이룸\n",
    "        2. `Selective Search`\n",
    "            - 인접한 영역끼리 `유사성(similarity)`을 측정해 작은 영역에서 큰 영역으로 점진적으로 통합해 나감\n",
    "            - 이러한 방법은 `R-CNN(CVPR 2014)`과 `Fast R-CNN(ICCV 2015)`에서 사용됨\n",
    "            - 기본적으로 이 방법은 `CPU`에서 동작하도록 라이브러리에 작성되어 있기 때문에 한 장의 이미지에 대해서<br>\n",
    "            약 2초 가량의 시간이 소요될 수 있음\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Object Detection(객체 검출) 정확도 측정 방법<br>\n",
    "<br>\n",
    "    - 성능 평가 지표: 정밀도(Precision)와 재현율(Recall)\n",
    "        - <img src=\"../markdown/precision_recall.png\" width=\"600\">\n",
    "        - TP(True Positive)\n",
    "            - 모델이 `객체`라고 `올바르게 판단`한 경우\n",
    "        - FP(False Positive)\n",
    "            - 모델이 `객체`라고 `잘못 판단`하여 탐지한 경우\n",
    "        - FN(False Negative)\n",
    "            - 모델이 `객체`가 아니라고 `잘못 판단`하여 탐지하지 않은 경우\n",
    "        - TN(True Negative)\n",
    "            - 모델이 `객체`가 아니라고 `올바르게 판단`한 경우\n",
    "        - TP + FP\n",
    "            - 모델이 `탐지`한 `모든` 객체의 수\n",
    "        - TP + FN\n",
    "            - `실제 정답 객체`의 수\n",
    "        - `Precision(정밀도)`\n",
    "            - $Precision=\\frac{TP}{TP+FP}$<br>\n",
    "<br>\n",
    "            - 모델이 정밀도만을 지향하게 된다면 더욱 엄격한 기준으로 판단을 하게 되고, 이렇게 되면 예측 결과 중 `FN`의<br>\n",
    "            숫자가 많아지게 됨\n",
    "        - `Recall(재현율)`\n",
    "            - $Recall=\\frac{TP}{TP+FN}$<br>\n",
    "<br>\n",
    "            - 모델이 재현율만을 지향하게 된다면 판단 기준이 상대적으로 관대해져서 정답을 예측하는 경우가 많아지고,<br>\n",
    "            이렇게 되면 예측 결과 중 `FP`의 숫자가 많아지게 됨\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mean Average Precision<br>\n",
    "<br>\n",
    "    - d\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Jaccard Overlap(or Intersection over Union, `IoU`)<br>\n",
    "<br>\n",
    "    - `IoU`란 두 `bounding box`가 겹치는 비율(`정도`)을 의미함\n",
    "        - <img src=\"../markdown/intersection_over_union.png\" width=\"500\">\n",
    "        - `IoU`가 주로 사용되는 경우로는 `성능 평가` 그리고 `NMS 계산`\n",
    "            - 성능 평가 예시: `mAP@0.5` -> 정답과 예측의 `IoU`가 50% 이상일 때 정답으로 판정하겠다는 의미\n",
    "            - `NMS 계산 예시`: 같은 클래스를 탐지한 `bounding boxes`끼리의 `IoU`가 50% 이상일 때 그 중 낮은<br>\n",
    "            `confidence`의 `bounding box`를 제거\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Non-Maximum Suppression(`NMS`)<br>\n",
    "<br>\n",
    "    - dd\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38cc0cca68228d4d18227abe74ed813685db17db46984279e4aabdddebf5f1ba"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
