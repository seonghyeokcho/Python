{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection(객체 탐지)\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이미지 내에서 `객체(물체)`를 인식하는 방법<br>\n",
    "<br>\n",
    "    1. classification: `분류`라고 불리는 전통적인 방법은 하나의 이미지를 입력으로 받아서<br>\n",
    "    해당 이미지가 어떠한 `class`의 이미지인지 `구분`(예측하는) 것<br>\n",
    "<br>\n",
    "    2. localization: 지역화, 국소화라는 뜻을 가진 이 방법은 말그대로 객체가 있을만한 곳을<br>\n",
    "    `bounding box`라고 하는 것을 통해 `위치`를 찾는(예측하는) 것\n",
    "        - 위 1,2번은 공통적으로 하나의 이미지에 하나의 객체에 대해서 작업을 수행함<br>\n",
    "<br>\n",
    "    3. object detection: 위 1,2번이 합쳐진 형태로, 객체의 `위치와 클래스`를 함께 찾는 두 가지의 작업을 수행하는 것\n",
    "        - 위 1,2번과 다른점은 1,2번은 하나의 이미지에 `단일 객체`에 대한 작업이고, `객체 탐지(object detection)`는<br>\n",
    "        `다수의 객체`에 대한 작업<br>\n",
    "<br>\n",
    "    4. instance segmentation: 이미지 내에 각 객체를 `픽셀 단위`로 예측하는 작업을 수행하는<br>\n",
    "    형태로, `object detection`에서 조금 더 발전된 형태의 작업을 수행하는 것\n",
    "        - 추가적으로 sementic segmentation과 차이점은 `군집화(clustering)`이냐 `개별적(individually)`이냐의 차이<br>\n",
    "<br>\n",
    "- 객체 탐지의 `두 가지 작업(Task)`에 대한 세부사항<br>\n",
    "<br>\n",
    "    - localization(위치결정): 이미지 안에 존재하는 객체의 `위치 정보`를 `경계상자(bounding box)`를 통해 찾는 것\n",
    "        - `위치 정보`: 더 정확하게는 객체가 있을 것 같은 경계상자의 `offset`을 찾는 것<br>\n",
    "        `i.e., bounding box regression`<br>\n",
    "<br>\n",
    "    - Classification(분류): 해당 경계상자에 포함되어 있는 객체가 무엇인지 분류하는 것<br>\n",
    "<br>\n",
    "- 객체 탐지 알고리즘(Algorithm)의 종류\n",
    "    - `One Stage Detector(or Algorithm)`\n",
    "        - 위 두 작업을 한 번에 수행\n",
    "        - 알고리즘: SSD(Single Shot Detection), YOLO(You Only Look Once) 등\n",
    "        - 특징: `two stage detectors`에 비해 상대적으로 연산 속도가 빠르고, 정확도는 낮음\n",
    "    - `Two Stage Detector(or Algorithm)`\n",
    "        - 위 두 작업을 구분하여 수행\n",
    "        - 알고리즘: `R-CNN` family(R-CNN, Fast R-CNN, Faster R-CNN, `Mask R-CNN`)\n",
    "            - `R-CNN`: Region-based Convolutional Neural Network(영역 기반 합성곱 신경망)\n",
    "            - `Mask R-CNN`: 객체(물체) 탐지도 수행하지만 주 목적은 Object Detection보다<br>\n",
    "            발전된 형태인 픽셀 단위 Object Detection 즉, `Image Instance Segmentation`(이미지 분할)\n",
    "        - 특징: `one stage detectors`에 비해 상대적으로 연산 속도가 느리고, 정확도는 높음\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Region proposal(영역 제안)<br>\n",
    "<br>\n",
    "    - 물체가 있을 법한 위치(영역)를 찾는 과정을 뜻하며, 이러한 영역을 `관심 영역(Region of interest, ROI)`이라고 함<br>\n",
    "<br>\n",
    "    - 영역 제안 방법\n",
    "        1. Sliding Window(미끄러지는 창)\n",
    "            - 이미지내에서 다양한 형태의 `윈도우(window)` 혹은 `커널(kernel)`이 이미지 전체를 슬라이딩하며 물체가<br>\n",
    "            존재하는지 확인함\n",
    "            - 다만 너무 많은 영역에 대하여 확인해야 한다는 단점이 존재함. 특히 특징 맵이 아니라 입력 이미지 자체에 대해서<br>\n",
    "            `CPU`장치를 이용해 슬라이딩을 진행하게 되면 넓은 입력 공간(input space)상에서 많은 영역에 대하여 확인해야<br>\n",
    "            하므로 속도가 느릴수 있음\n",
    "            - 반례로 `Faster R-CNN(NIPS 2015)`에서는 `CPU`가 아닌 `GPU`에서 이 작업을 수행하도록 작성되어<br>\n",
    "            속도 측면에서 비약적인 발전을 이룸\n",
    "        2. Selective Search(선택적 탐색)\n",
    "            - 인접한 영역끼리 `유사성(similarity)`을 측정해 작은 영역에서 큰 영역으로 점진적으로 통합해 나감\n",
    "            - 이러한 방법은 `R-CNN(CVPR 2014)`과 `Fast R-CNN(ICCV 2015)`에서 사용됨\n",
    "            - 기본적으로 이 방법은 `CPU`에서 동작하도록 라이브러리에 작성되어 있기 때문에 한 장의 이미지에 대해서<br>\n",
    "            약 2초 가량의 시간이 소요될 수 있음\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Object Detection(객체 검출) 성능 평가 지표<br>\n",
    "<br>\n",
    "    - Jaccard Overlap(or Intersection over Union, `IoU`)<br>\n",
    "<br>\n",
    "        - `IoU`란 두 `bounding box`가 겹치는 비율(`정도`)을 의미함\n",
    "            - <img src=\"../markdown/intersection_over_union.png\" width=\"500\">\n",
    "            - `IoU`가 주로 사용되는 경우로는 `성능 평가` 그리고 `NMS 계산`\n",
    "                - 성능 평가 예시: `mAP@0.5` -> multi class에 대한 AP(Average Precision)들의 평균(Mean)을 구할 때<br>\n",
    "                정답과 예측의 `IoU = 0.5`를 `임계점(Threshold)`으로 하여 그 이상의 값에 해당하는 것을 정답으로 판정하겠다는 의미\n",
    "                - NMS 계산 예시: 같은 클래스를 탐지한 `bounding boxes`끼리의 `IoU`가 0.5 이상일 때 그 중 낮은<br>\n",
    "                `confidence`의 `bounding box`를 제거<br>\n",
    "<br>\n",
    "    - Confusion Matrix(혼동 행렬)\n",
    "        - <img src=\"../markdown/confusion_matrix.png\" width=\"600\">\n",
    "        - TP(True Positive)\n",
    "            - 모델이 객체라고 `올바르게 판단`한 경우<br>\n",
    "<br>\n",
    "        - FP(False Positive)\n",
    "            - 모델이 객체라고 `잘못 판단`하여 탐지한 경우<br>\n",
    "<br>\n",
    "        - FN(False Negative)\n",
    "            - 모델이 객체가 아니라고 `잘못 판단`하여 탐지하지 않은 경우<br>\n",
    "<br>\n",
    "        - TN(True Negative)\n",
    "            - 모델이 객체가 아니라고 `올바르게 판단`한 경우<br>\n",
    "<br>\n",
    "        - TP + FP\n",
    "            - 모델이 `탐지한 모든 객체`의 수<br>\n",
    "<br>\n",
    "        - TP + FN\n",
    "            - `실제 정답 객체`의 수<br>\n",
    "<br>\n",
    "    - Precision(정밀도)\n",
    "        - $Precision=\\frac{TP}{TP+FP}$<br>\n",
    "<br>\n",
    "        - 모델의 관점에서 모델이 객체라고 탐지한 모든 경우에 대해 실제 정답의 비율(정도)\n",
    "        - 모델이 정밀도만을 지향하게 된다면 더욱 엄격한 기준으로 판단을 하게 되고, 이렇게 되면 예측 결과 중 `FN`의<br>\n",
    "        숫자가 많아지게 됨\n",
    "    - Recall(재현율)\n",
    "        - $Recall=\\frac{TP}{TP+FN}$<br>\n",
    "<br>\n",
    "        - 실제 데이터의 관점에서 실제 정답에 대해 모델이 객체라고 탐지한 비율(정도)\n",
    "        - 모델이 재현율만을 지향하게 된다면 판단 기준이 상대적으로 관대해져서 정답을 예측하는 경우가 많아지고,<br>\n",
    "        이렇게 되면 예측 결과 중 `FP`의 숫자가 많아지게 됨<br>\n",
    "<br>\n",
    "    - F-Score(가중 조화 평균)\n",
    "        - $F_\\beta\\ Score=\\frac{1}{\\alpha\\frac{1}{Precision}+(1-\\alpha)\\frac{1}{Recall}}=\\frac{(\\beta^2+1)\\times Precision\\times Recall}{\\beta^2\\times Precision+Recall}$<br>\n",
    "<br>\n",
    "        - 위 식에서 정밀도와 재현율에 가중치 $\\alpha$를 동일하게 각각 0.5씩 주었을 때 $\\beta=1$이 되고, 이 경우를 F1-Score라고 함<br>\n",
    "<br>\n",
    "        - $F_1\\ Score=H(harmonic\\ mean)=\\left(\\frac{\\frac{1}{Precision}+\\frac{1}{Recall}}{2}\\right)^{-1}=\\frac{2\\times Precision\\times Recall}{Precision+Recall}$<br>\n",
    "<br>\n",
    "            - $H=\\frac{G^2}{A}\\quad where\\quad A=\\frac{Precision+Recall}{2},\\ G=\\sqrt{Precision\\times Recall}$<br>\n",
    "<br>\n",
    "            - 위 식 F1-Score를 해석해보자면 정밀도와 재현율의 역수는 즉, TP에 대한 모델이 탐지한 객체와 실제 정답 데이터의<br>\n",
    "            비율을 뜻하는데 이것들의 산술평균을 구하고 다시 역수를 취해 원래대로 되돌림<br>\n",
    "<br>\n",
    "    - Precision-Recall Curve(PR 곡선)<br>\n",
    "<br>\n",
    "        - ㅇㅇ\n",
    "    - Average Precision(AP)<br>\n",
    "<br>\n",
    "        - dd\n",
    "    - mean Average Precision(mAP)<br>\n",
    "<br>\n",
    "        - d<br>\n",
    "<br>\n",
    "- 그 외 다른 성능 평가 지표\n",
    "    - `Fall-out(위양성율)`\n",
    "        - $Fallout=\\frac{FP}{FP+TN}$<br>\n",
    "<br>\n",
    "        - 실제 데이터의 관점에서 모든 오답에 대해 모델이 객체라고 잘못 탐지한 비율(정도)\n",
    "    - `Accuracy(정확도)`\n",
    "        - $Accuracy=\\frac{TP+TN}{TP+FP+FN+TN}$<br>\n",
    "<br>\n",
    "        - dd\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Non-Maximum Suppression(`NMS`)<br>\n",
    "<br>\n",
    "    - dd\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92 0.9387755102040817 0.9293877551020409 0.9293403409880339 0.9292929292929292 0.9222222222222223\n"
     ]
    }
   ],
   "source": [
    "from math import *\n",
    "\n",
    "\n",
    "def calc_harmonic_mean(TP, FP, FN, TN):\n",
    "    P = TP / (TP + FP)\n",
    "    R = TP / (TP + FN)\n",
    "    A = (P + R) / 2\n",
    "    G = sqrt(P * R)\n",
    "    H = G**2 / A\n",
    "    AC = (TP + TN) / (TP + FP + FN + TN)\n",
    "    \n",
    "    return P, R, A, G, H, AC\n",
    "\n",
    "precision, recall, average, geometric_mean, harmonic_mean, accuracy = calc_harmonic_mean(46, 4, 3, 37)\n",
    "print(precision, recall, average, geometric_mean, harmonic_mean, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38cc0cca68228d4d18227abe74ed813685db17db46984279e4aabdddebf5f1ba"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
