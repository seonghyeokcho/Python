{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection(객체 탐지)\n",
    "<hr>\n",
    "\n",
    "- 이미지 내에서 객체(물체)를 인식하는 방법에는 다양한 유형이 존재함\n",
    "    - `classification`: `분류`라고 불리는 전통적인 방법은 하나의 이미지를 입력으로 받아서<br>\n",
    "    해당 이미지가 어떠한 `class`의 이미지인지 구분(예측하는) 것\n",
    "    - `localization`: 지역화, 국소화라는 뜻을 가진 이 방법은 말그대로 객체(물체)가 있을만한 곳을<br>\n",
    "    `bounding box`라고 하는 것을 통해 `위치`를 찾는(예측하는) 것\n",
    "        - 위 1,2번은 공통적으로 하나의 이미지에 하나의 객체(물체)에 대해서 `분류` 혹은 `위치결정`을 함\n",
    "    - `object detection`: 위 `classification`과 `localization`방법이 합쳐진 형태로,<br>\n",
    "    하나의 이미지에 `다수`의 객체(물체)가 존재하는 상황에서 `각 객체(물체)의 위치와 클래스`를 함께 찾는<br>\n",
    "    두 가지의 작업을 수행하는 것\n",
    "    4. `image segmentation`: 이미지 내에 각 객체(물체)를 `픽셀 단위`로 `분할`하는 작업을 수행하는<br>\n",
    "    형태로, `object detection`에서 조금 더 발전된 형태의 작업을 수행하는 것\n",
    "- `Object Detection`의 두 가지 작업(task)에 대한 세부사항\n",
    "    - `bounding box regression(위치결정)`: 이미지 안에 존재하는 객체(물체)의 `위치 정보`를<br>\n",
    "    `bounding box`를 통해 찾는 것\n",
    "        - `위치 정보`: 더 정확하게는 객체(물체)가 있을 것 같은 `경계상자`의 `offset`을 찾는 것\n",
    "    - Classification(분류): 해당 `bounding box`에 포함되어 있는 객체(물체)가 무엇인지 `분류`하는 것\n",
    "    - Regression과 Classification을 수행하기 위해서 일반적으로 두 단계가 필요\n",
    "        - 1단계. 이미지 내에 객체(물체)가 있을 만한 위치에 `bounding box`를 나열함\n",
    "            - 이때 `bounding box`내의 영역을 `ROI(regions of interest)` 즉, 관심 영역<br>\n",
    "            이라고 볼 수 있고, 이러한 방법을 `Region proposals`이라고 칭함\n",
    "        - 2단계. 각각의 `bounding box`에 대해 `특징 추출기(feature extractor)`라는 것을 통해 특징을 추출하여<br>\n",
    "        이것을 토대로 `Regression`과 `Classification`을 수행\n",
    "            - 여기서 말하는 `feature extractor`로는 `CNN(Convolutional Neural Network)`가<br>\n",
    "            사용됨\n",
    "    - Object Detection 알고리즘은 크게 두 가지로 구분됨\n",
    "        - `One Stage Detectors(or Algorithm)`\n",
    "            - 위 두 단계를 한 번에 수행\n",
    "            - 알고리즘: SSD(Single Shot Detection), YOLO(You Only Look Once) 등\n",
    "            - 특징: `two stage detectors`에 비해 상대적으로 연산 속도가 빠르고, 정확도는 낮지만 큰 차이는<br>\n",
    "            없거나 더 좋은 경우도 있음\n",
    "        - `Two Stage Detectors(or Algorithm)`\n",
    "            - 위 두 단계를 구분하여 수행\n",
    "            - 알고리즘: `R-CNN` family(R-CNN, Fast R-CNN, Faster R-CNN, `Mask R-CNN`)\n",
    "                - `R-CNN`: Region-based Convolutional Neural Network(영역 기반 합성곱 신경망)\n",
    "                - `Mask R-CNN`: 객체(물체) 탐지도 수행하지만 주 목적은 Object Detection보다<br>\n",
    "                발전된 형태인 픽셀 단위 Object Detection 즉, `Image Segmentation`(이미지 분할)\n",
    "            - 특징: `one stage detectors`에 비해 상대적으로 연산 속도가 느리고, 정확도는 높다.\n",
    "- Object Detection은 지도학습과 비지도학습 중 `지도학습`에 해당함\n",
    "    - Regression과 Classification 이라는 두가지 작업에 해당하기 때문에 각각에 대한 레이블이 필요함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- R-CNN 계열 기법들의 발전 방향 및 장단점 분석\n",
    "    - R-CNN(CVPR 2014)\n",
    "        - 장점: CNN을 이용해 각 Region의 클래스를 분류하는 기법으로 딥러닝 기법을 효과적으로<br>\n",
    "        `object detection` 분야에 적용함으로써 당시 기준으로 큰 성능 향상을 이끌어 냄\n",
    "        - 단점: 다양한 구성 요소(component) 붙여 넣은 방식이라서 성능이 낮음뿐만아니라 속도가 느리고,<br>\n",
    "        전체 프레임워크를 end-to-end 방식으로 학습할 수 없음. 따라서 전방위적인 최적의 해결책<br>\n",
    "        (Global Optimal Solution) 을 찾기 어려움\n",
    "    - Fast R-CNN(ICCV 2015)\n",
    "        - 장점: Selective Search를 제외한 다른 부분(Feature Extraction, RoI Pooling, Region<br>\n",
    "        Classification, Bounding box Regression)의 단계(step)를 하나의 네트워크(end-to-end)로<br>\n",
    "        묶어서 학습이 가능하도록 만들었기 때문에 상대적으로 R-CNN에 비해 Global Optimal Solution을<br>\n",
    "        잘 찾을수 있게 됨\n",
    "        - 단점: 하지만 여전히 영역 제안(Region Proposals)을 위한 Selective Search는 CPU에서 수행<br>\n",
    "        해야되므로 이 부분이 bottleneck(병목 현상)으로 작용되어 속도 측면에서 아직도 많이 느림\n",
    "    - Faster R-CNN(NIPS 2015)\n",
    "        - 장점: 기존의 Selective Search 방식 대신 GPU에서 작업이 이루어지는 RPN(Region Proposal Networks)<br>\n",
    "        을 제안, 이를 사용하여 처리 시간이 상당히 줄어들었고, 전체 프레임워크를 하나의 네트워크(end-to-end)로<br>\n",
    "        학습하여 당시 비약적인 성능향상을 이루어서 현재까지도 Baseline Model로 채택되고 있음\n",
    "        - 단점: 여전히 많은 구성 요소(Component)가 존재하여 전체 구조체(architecture)가 여전히 많이 복잡할<br>\n",
    "        뿐만아니라 Region Classification 단계를 진행할 때 각각의 Region에 대한 특징 벡터가 개별적으로<br>\n",
    "        구분되어 FC(Fully-Connected) layer로 전달(Forwards)됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Region proposal\n",
    "    - 물체가 있을 법한 위치를 찾는 과정을 뜻함\n",
    "    1. `Sliding Window`\n",
    "        - 이미지내에서 다양한 형태의 `윈도우(window)` 혹은 `커널(kernel)`이 슬라이딩하며 물체가 존재하는지 확인함\n",
    "            - 다만 너무 많은 영역에 대하여 확인해야 한다는 단점이 존재함. 특히 특징 맵이 아니라 입력 이미지 자체에<br>\n",
    "            대해서 `CPU`장치를 이용해 슬라이딩을 진행하게 되면 넓은 입력 공간(input space)상에서 많은 영역에<br>\n",
    "            대하여 확인해야 하므로 속도가 느릴수 있음\n",
    "            - 반례로 `Faster R-CNN(NIPS 2015)`에서는 `CPU`가 아닌 `GPU`에서 이 작업을 수행하도록 작성되어<br>\n",
    "            속도 측면에서 비약적인 발전을 이룸\n",
    "    2. `Selective Search`\n",
    "        - 인접한 영역(region)끼리 `유사성(similarity)`을 측정해 작은 영역에서 큰 영역으로 점진적으로 통합해 나감\n",
    "            - 이러한 방법은 `R-CNN(CVPR 2014)`과 `Fast R-CNN(ICCV 2015)`에서 사용되는<br>\n",
    "            region proposal 방법임\n",
    "            - 기본적으로 이 방법은 `CPU`에서 동작하도록 라이브러리에 작성되어 있기 때문에 한 장의 이미지에 대해서<br>\n",
    "            약 2초 가량의 시간이 소요될 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Object Detection(객체 검출) 정확도 측정 방법\n",
    "    - 성능 평가 지표: 정밀도(Precision)와 재현율(Recall)\n",
    "        - <img src=\"../markdown/precision_recall.png\" width=\"600\">\n",
    "        - Precision(정밀도)\n",
    "            - 모델이 `탐지한 객체` 중에 `실제 정답인 객체`의 수(TP) / 모델이 `탐지한 모든 객체`의 수(TP + FP)\n",
    "        - Recall(재현율)\n",
    "            - 모델이 `탐지한 객체` 중에 `실제 정답인 객체`의 수(TP) / `실제 정답인 객체`의 수(TP + FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [\"1\",\"2\",\"3\"]\n",
    "l.pop(2)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../markdown/SSD_architecture.png', '../markdown/precision_recall.png', '../markdown/intersection_over_union.png']\n"
     ]
    }
   ],
   "source": [
    "# 중복없이 랜덤으로 n개 만큼의 이미지 경로 가져오기\n",
    "import glob\n",
    "import random\n",
    "\n",
    "\n",
    "images = []\n",
    "for i in range(3):\n",
    "    while True:\n",
    "        image_path = random.choice(glob.glob(\"../markdown/*.png\"))\n",
    "        if image_path not in images:\n",
    "            break\n",
    "    images.append(image_path)\n",
    "print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38cc0cca68228d4d18227abe74ed813685db17db46984279e4aabdddebf5f1ba"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
