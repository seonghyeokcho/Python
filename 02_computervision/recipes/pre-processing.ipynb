{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공항 cctv 이상행동 감지\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 모델 & 설정 파일\n",
    "model = \"pre-trained/yolo_v3/yolov3.weights\"\n",
    "config = \"pre-trained/yolo_v3/yolov3.cfg\"\n",
    "class_labels = \"pre-trained/yolo_v3/coco.names\"\n",
    "confThreshold = 0.5\n",
    "nmsThreshold = 0.4\n",
    "magThreshold = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yolo_82', 'yolo_94', 'yolo_106']\n"
     ]
    }
   ],
   "source": [
    "# 네트워크 생성\n",
    "network = cv2.dnn.readNet(model, config)\n",
    "\n",
    "if network.empty():\n",
    "    print(\"Network open failed!\")\n",
    "\n",
    "# 클래스 이름 불러오기\n",
    "classes = []\n",
    "with open(class_labels, \"rt\") as f:\n",
    "    classes = f.read().rstrip(\"\\n\").split(\"\\n\")\n",
    "\n",
    "# # 각각의 클래스에 대한 랜덤한 색상\n",
    "# colors = np.random.uniform(0, 255, (len(classes), 3))\n",
    "\n",
    "# 출력 레이어 이름 받아오기\n",
    "output_layers = list(network.getUnconnectedOutLayersNames())\n",
    "print(output_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video open succeed!\n",
      "1920 1080\n",
      "25\n",
      "40\n",
      "(270, 480)\n"
     ]
    }
   ],
   "source": [
    "video = cv2.VideoCapture(\"dataset/alchera_cctv_data/rush/camera1_20191022_100307.avi\")\n",
    "\n",
    "if video.isOpened():\n",
    "    print(\"Video open succeed!\")\n",
    "\n",
    "WIDTH = round(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "HEIGHT = round(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "print(WIDTH, HEIGHT)\n",
    "\n",
    "FPS = round(video.get(cv2.CAP_PROP_FPS))\n",
    "print(FPS)\n",
    "DELAY = round(1000 / FPS)\n",
    "print(DELAY)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "writer = cv2.VideoWriter(\"videos/cctv.mp4\", fourcc, FPS, (WIDTH, HEIGHT))\n",
    "\n",
    "# 파네백 옵티컬플로우 클래스 인스턴스 생성\n",
    "farneback = cv2.FarnebackOpticalFlow_create()\n",
    "\n",
    "_, prev_frame = video.read()\n",
    "prev_frame = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "prev_frame = cv2.resize(prev_frame, (0, 0), None, 1/4, 1/4, interpolation=cv2.INTER_AREA)\n",
    "print(prev_frame.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video open succeed!\n",
      "1920 1080\n",
      "25\n",
      "40\n",
      "Video was interrupted!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rush\n",
    "video = cv2.VideoCapture(\"dataset/alchera_cctv_data/rush/camera1_20191022_100307.avi\")\n",
    "# wrong direction\n",
    "# video = cv2.VideoCapture(\"dataset/alchera_cctv_data/wrong_direction/camera2_20191021_163409.avi\")\n",
    "\n",
    "if video.isOpened():\n",
    "    print(\"Video open succeed!\")\n",
    "\n",
    "WIDTH = round(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "HEIGHT = round(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "print(WIDTH, HEIGHT)\n",
    "\n",
    "FPS = round(video.get(cv2.CAP_PROP_FPS))\n",
    "print(FPS)\n",
    "DELAY = round(1000 / FPS)\n",
    "print(DELAY)\n",
    "\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "writer = cv2.VideoWriter(\"videos/cctv.mp4\", fourcc, FPS, (WIDTH, HEIGHT))\n",
    "\n",
    "# 파네백 옵티컬플로우 클래스 인스턴스 생성\n",
    "farneback = cv2.FarnebackOpticalFlow_create()\n",
    "\n",
    "_, prev_frame = video.read()\n",
    "prev_frame = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "prev_frame = cv2.resize(prev_frame, (0, 0), None, 1/4, 1/4, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# 실행\n",
    "while True:\n",
    "    retval, image = video.read()\n",
    "    \n",
    "    if not retval:\n",
    "        break\n",
    "    \n",
    "    next_frame = cv2.cvtColor(image.copy(), cv2.COLOR_BGR2GRAY)\n",
    "    next_frame = cv2.resize(next_frame, (0, 0), None, 1/4, 1/4, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    \n",
    "    # 블롭 생성\n",
    "    blob = cv2.dnn.blobFromImage(image, 1/255., (320, 320), swapRB=True)\n",
    "    network.setInput(blob)\n",
    "    # 추론\n",
    "    outs = network.forward(output_layers)\n",
    "    # outs는 3개의 ndarray 리스트.\n",
    "    # outs[0].shape=(507, 85), 13*13*3=507\n",
    "    # outs[1].shape=(2028, 85), 26*26*3=2028\n",
    "    # outs[2].shape=(8112, 85), 52*52*3=8112\n",
    "    \n",
    "    HEIGHT, WIDTH = image.shape[:2]\n",
    "    \n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    \n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            # detection: 4(bounding box) + 1(objectness score) + 80(class confidence)\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > confThreshold:\n",
    "                # 바운딩 박스 중심 좌표 & 박스 크기\n",
    "                cx = int(detection[0] * WIDTH)\n",
    "                cy = int(detection[1] * HEIGHT)\n",
    "                bw = int(detection[2] * WIDTH)\n",
    "                bh = int(detection[3] * HEIGHT)\n",
    "                \n",
    "                # 바운딩 박스 좌상단 좌표: 중심좌표 - 가로 세로 크기의 반 = 좌상단 좌표\n",
    "                x = int(cx - (bw/2))\n",
    "                y = int(cy - (bh/2))\n",
    "                \n",
    "                boxes.append([x, y, bw, bh])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(int(class_id))\n",
    "    \n",
    "    # 비최대 억제(NMS, Non-Maximum Suppression)\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, confThreshold, nmsThreshold)\n",
    "    \n",
    "    for i in indices:\n",
    "        x, y, w, h = boxes[i]\n",
    "        label = f\"{classes[class_ids[i]]}: {confidences[i]:.2f}\"\n",
    "        cv2.rectangle(image, (x, y, w, h), (0, 255, 0), 2)\n",
    "        cv2.putText(image, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # 파네벡 옵티컬 플로우 계산\n",
    "        flow = farneback.calc(prev_frame, next_frame, None)\n",
    "        \n",
    "        magnitude, angle = cv2.cartToPolar(flow[..., 0], flow[..., 1], angleInDegrees=True)\n",
    "        \n",
    "        meanMag = np.mean(magnitude[image[y:y+h, x:x+w]])\n",
    "        meanAngle = np.mean(angle)\n",
    "        \n",
    "        if meanMag > 1.8:\n",
    "            label = \"Anomaly Detected: Rush\"\n",
    "            cv2.putText(image, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "        # print(\"mean value of magnitude:\", meanMag)\n",
    "        # print(\"mean value of angle:\", meanAngle)\n",
    "        # if 10 <= meanAngle or meanAngle <= 260:\n",
    "        #     label = \"Anomaly Detected: Wrong Direction\"\n",
    "        #     cv2.putText(image, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    writer.write(image)  # 동영상 저장\n",
    "    \n",
    "    cv2.namedWindow(\"frame\", cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(\"frame\", 960, 540)\n",
    "    cv2.imshow(\"frame\", image)\n",
    "    \n",
    "    if cv2.waitKey(DELAY) == 27:\n",
    "        print(\"Video was interrupted!\")\n",
    "        break\n",
    "\n",
    "video.release()  # 할당된 자원을 해제\n",
    "writer.release()    # 동영상 상자를 닫음\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video.release()  # 할당된 자원을 해제\n",
    "writer.release()    # 동영상 상자를 닫음\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [0,2,3,4,5]\n",
    "np.argmax(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video open succeed!\n",
      "1920 1080\n",
      "25\n",
      "40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파네백 옵티컬플로우 계산 예제\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 진행 방향을 Hue 값으로 표현\n",
    "def draw_flow_as_HUE(HSV, flow):\n",
    "    magnitude, angle = cv2.cartToPolar(flow[..., 0], flow[..., 1], angleInDegrees=True)\n",
    "    HSV[..., 0] = angle / 2\n",
    "    HSV[..., 2] = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "    BGR = cv2.cvtColor(HSV, cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    return BGR\n",
    "\n",
    "\n",
    "# 진행 방향을 직선으로 표현\n",
    "def draw_flow_as_line(next_image, flow, step=16):\n",
    "    h, w = next_image.shape[:2]\n",
    "    y, x = np.mgrid[step/2:h:step, step/2:w:step].reshape(2, -1).astype(int)\n",
    "    fx, fy = flow[y, x].T\n",
    "    lines = np.vstack([x, y, x+fx, y+fy]).T.reshape(-1, 2, 2)\n",
    "    lines = np.int32(lines + 0.5)\n",
    "    visualization = cv2.cvtColor(next_image, cv2.COLOR_GRAY2BGR)\n",
    "    cv2.polylines(visualization, lines, False, (0, 255, 255), lineType=cv2.LINE_AA)\n",
    "\n",
    "    for (x1, y1), (_x2, _y2) in lines:\n",
    "        cv2.circle(visualization, (x1, y1), 1, (0, 128, 255), -1, lineType=cv2.LINE_AA)\n",
    "\n",
    "    return visualization\n",
    "\n",
    "\n",
    "video = cv2.VideoCapture(\"dataset/alchera_cctv_data/rush/camera1_20191015_140659.avi\")\n",
    "\n",
    "if video.isOpened():\n",
    "    print(\"Video open succeed!\")\n",
    "\n",
    "WIDTH = round(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "HEIGHT = round(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "print(WIDTH, HEIGHT)\n",
    "\n",
    "FPS = round(video.get(cv2.CAP_PROP_FPS))\n",
    "print(FPS)\n",
    "DELAY = round(1000 / FPS)\n",
    "print(DELAY)\n",
    "\n",
    "retval, prev_frame = video.read()\n",
    "\n",
    "if not retval:\n",
    "    print(\"frame read failed!\")\n",
    "\n",
    "prev_frame_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# prev_frame과 같은 크기 & 같은 타입의 0으로 초기화된 HSV 색 공간을 정의하고 S 평면을 255로 초기화\n",
    "HSV = np.zeros_like(prev_frame)\n",
    "HSV[..., 1] = 255  # Saturation = 255\n",
    "\n",
    "# 파네백 옵티컬플로우 클래스 인스턴스 생성\n",
    "farneback = cv2.FarnebackOpticalFlow_create()\n",
    "\n",
    "# 매 프레임 처리\n",
    "while True:\n",
    "    retval, next_frame = video.read()\n",
    "    \n",
    "    if not retval:\n",
    "        break\n",
    "    \n",
    "    next_frame_gray = cv2.cvtColor(next_frame, cv2.COLOR_BGR2GRAY)\n",
    "    flow = farneback.calc(prev_frame_gray, next_frame_gray, None)\n",
    "    # flow = cv2.calcOpticalFlowFarneback(prev_frame_gray, next_frame_gray, None, 0.5, 3, 13, 10, 5, 1.1, 0)\n",
    "    \n",
    "    cv2.namedWindow(\"frame\", cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(\"frame\", 480, 270)\n",
    "    cv2.imshow(\"frame\", next_frame)\n",
    "    \n",
    "    # 진행 방향을 Hue 값으로 표현\n",
    "    cv2.namedWindow(\"hue flow\", cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(\"hue flow\", 480, 270)\n",
    "    cv2.imshow(\"hue flow\", draw_flow_as_HUE(HSV, flow))\n",
    "    \n",
    "    # 진행 방향을 직선으로 표현\n",
    "    cv2.namedWindow(\"line flow\", cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(\"line flow\", 480, 270)\n",
    "    cv2.imshow(\"line flow\", draw_flow_as_line(next_frame_gray, flow))\n",
    "    \n",
    "    if cv2.waitKey(DELAY) == 27:\n",
    "        print(\"Video was interrupted!\")\n",
    "        break\n",
    "    \n",
    "    prev_frame_gray = next_frame_gray\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38cc0cca68228d4d18227abe74ed813685db17db46984279e4aabdddebf5f1ba"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
