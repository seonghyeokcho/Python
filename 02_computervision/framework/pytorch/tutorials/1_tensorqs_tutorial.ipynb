{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n`\ud30c\uc774\ud1a0\uce58(PyTorch) \uae30\ubcf8 \uc775\ud788\uae30 <intro.html>`_ ||\n`\ube60\ub978 \uc2dc\uc791 <quickstart_tutorial.html>`_ ||\n**\ud150\uc11c(Tensor)** ||\n`Dataset\uacfc Dataloader <data_tutorial.html>`_ ||\n`\ubcc0\ud615(Transform) <transforms_tutorial.html>`_ ||\n`\uc2e0\uacbd\ub9dd \ubaa8\ub378 \uad6c\uc131\ud558\uae30 <buildmodel_tutorial.html>`_ ||\n`Autograd <autogradqs_tutorial.html>`_ ||\n`\ucd5c\uc801\ud654(Optimization) <optimization_tutorial.html>`_ ||\n`\ubaa8\ub378 \uc800\uc7a5\ud558\uace0 \ubd88\ub7ec\uc624\uae30 <saveloadrun_tutorial.html>`_\n\n\ud150\uc11c(Tensor)\n==========================================================================\n\n\ud150\uc11c(tensor)\ub294 \ubc30\uc5f4(array)\uc774\ub098 \ud589\ub82c(matrix)\uacfc \ub9e4\uc6b0 \uc720\uc0ac\ud55c \ud2b9\uc218\ud55c \uc790\ub8cc\uad6c\uc870\uc785\ub2c8\ub2e4.\nPyTorch\uc5d0\uc11c\ub294 \ud150\uc11c\ub97c \uc0ac\uc6a9\ud558\uc5ec \ubaa8\ub378\uc758 \uc785\ub825(input)\uacfc \ucd9c\ub825(output), \uadf8\ub9ac\uace0 \ubaa8\ub378\uc758 \ub9e4\uac1c\ubcc0\uc218\ub4e4\uc744 \ubd80\ud638\ud654(encode)\ud569\ub2c8\ub2e4.\n\n\ud150\uc11c\ub294 GPU\ub098 \ub2e4\ub978 \ud558\ub4dc\uc6e8\uc5b4 \uac00\uc18d\uae30\uc5d0\uc11c \uc2e4\ud589\ud560 \uc218 \uc788\ub2e4\ub294 \uc810\ub9cc \uc81c\uc678\ud558\uba74 `NumPy <https://numpy.org>`_ \uc758 ndarray\uc640 \uc720\uc0ac\ud569\ub2c8\ub2e4.\n\uc2e4\uc81c\ub85c \ud150\uc11c\uc640 NumPy \ubc30\uc5f4(array)\uc740 \uc885\uc885 \ub3d9\uc77c\ud55c \ub0b4\ubd80(underly) \uba54\ubaa8\ub9ac\ub97c \uacf5\uc720\ud560 \uc218 \uc788\uc5b4 \ub370\uc774\ud130\ub97c \ubcf5\uc218\ud560 \ud544\uc694\uac00 \uc5c6\uc2b5\ub2c8\ub2e4. (`bridge-to-np-label` \ucc38\uace0)\n\ud150\uc11c\ub294 \ub610\ud55c (`Autograd <autogradqs_tutorial.html>`__ \uc7a5\uc5d0\uc11c \uc0b4\ud3b4\ubcfc) \uc790\ub3d9 \ubbf8\ubd84(automatic differentiation)\uc5d0 \ucd5c\uc801\ud654\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.\nndarray\uc5d0 \uc775\uc219\ud558\ub2e4\uba74 Tensor API\ub97c \ubc14\ub85c \uc0ac\uc6a9\ud560 \uc218 \uc788\uc744 \uac83\uc785\ub2c8\ub2e4. \uc544\ub2c8\ub77c\uba74, \uc544\ub798 \ub0b4\uc6a9\uc744 \ud568\uaed8 \ubcf4\uc2dc\uc8e0!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud150\uc11c(tensor) \ucd08\uae30\ud654\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\ud150\uc11c\ub294 \uc5ec\ub7ec\uac00\uc9c0 \ubc29\ubc95\uc73c\ub85c \ucd08\uae30\ud654\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ub2e4\uc74c \uc608\ub97c \uc0b4\ud3b4\ubcf4\uc138\uc694:\n\n**\ub370\uc774\ud130\ub85c\ubd80\ud130 \uc9c1\uc811(directly) \uc0dd\uc131\ud558\uae30**\n\n\ub370\uc774\ud130\ub85c\ubd80\ud130 \uc9c1\uc811 \ud150\uc11c\ub97c \uc0dd\uc131\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ub370\uc774\ud130\uc758 \uc790\ub8cc\ud615(data type)\uc740 \uc790\ub3d9\uc73c\ub85c \uc720\ucd94\ud569\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = [[1, 2],[3, 4]]\nx_data = torch.tensor(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**NumPy \ubc30\uc5f4\ub85c\ubd80\ud130 \uc0dd\uc131\ud558\uae30**\n\n\ud150\uc11c\ub294 NumPy \ubc30\uc5f4\ub85c \uc0dd\uc131\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. (\uadf8 \ubc18\ub300\ub3c4 \uac00\ub2a5\ud569\ub2c8\ub2e4 - `bridge-to-np-label` \ucc38\uace0)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "np_array = np.array(data)\nx_np = torch.from_numpy(np_array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**\ub2e4\ub978 \ud150\uc11c\ub85c\ubd80\ud130 \uc0dd\uc131\ud558\uae30:**\n\n\uba85\uc2dc\uc801\uc73c\ub85c \uc7ac\uc815\uc758(override)\ud558\uc9c0 \uc54a\ub294\ub2e4\uba74, \uc778\uc790\ub85c \uc8fc\uc5b4\uc9c4 \ud150\uc11c\uc758 \uc18d\uc131(\ubaa8\uc591(shape), \uc790\ub8cc\ud615(datatype))\uc744 \uc720\uc9c0\ud569\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x_ones = torch.ones_like(x_data) # x_data\uc758 \uc18d\uc131\uc744 \uc720\uc9c0\ud569\ub2c8\ub2e4.\nprint(f\"Ones Tensor: \\n {x_ones} \\n\")\n\nx_rand = torch.rand_like(x_data, dtype=torch.float) # x_data\uc758 \uc18d\uc131\uc744 \ub36e\uc5b4\uc501\ub2c8\ub2e4.\nprint(f\"Random Tensor: \\n {x_rand} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**\ubb34\uc791\uc704(random) \ub610\ub294 \uc0c1\uc218(constant) \uac12\uc744 \uc0ac\uc6a9\ud558\uae30:**\n\n``shape`` \uc740 \ud150\uc11c\uc758 \ucc28\uc6d0(dimension)\uc744 \ub098\ud0c0\ub0b4\ub294 \ud29c\ud50c(tuple)\ub85c, \uc544\ub798 \ud568\uc218\ub4e4\uc5d0\uc11c\ub294 \ucd9c\ub825 \ud150\uc11c\uc758 \ucc28\uc6d0\uc744 \uacb0\uc815\ud569\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "shape = (2,3,)\nrand_tensor = torch.rand(shape)\nones_tensor = torch.ones(shape)\nzeros_tensor = torch.zeros(shape)\n\nprint(f\"Random Tensor: \\n {rand_tensor} \\n\")\nprint(f\"Ones Tensor: \\n {ones_tensor} \\n\")\nprint(f\"Zeros Tensor: \\n {zeros_tensor}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--------------\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud150\uc11c\uc758 \uc18d\uc131(Attribute)\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\ud150\uc11c\uc758 \uc18d\uc131\uc740 \ud150\uc11c\uc758 \ubaa8\uc591(shape), \uc790\ub8cc\ud615(datatype) \ubc0f \uc5b4\ub290 \uc7a5\uce58\uc5d0 \uc800\uc7a5\ub418\ub294\uc9c0\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tensor = torch.rand(3,4)\n\nprint(f\"Shape of tensor: {tensor.shape}\")\nprint(f\"Datatype of tensor: {tensor.dtype}\")\nprint(f\"Device tensor is stored on: {tensor.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--------------\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud150\uc11c \uc5f0\uc0b0(Operation)\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\uc804\uce58(transposing), \uc778\ub371\uc2f1(indexing), \uc2ac\ub77c\uc774\uc2f1(slicing), \uc218\ud559 \uacc4\uc0b0, \uc120\ud615 \ub300\uc218,\n\uc784\uc758 \uc0d8\ud50c\ub9c1(random sampling) \ub4f1, 100\uac00\uc9c0 \uc774\uc0c1\uc758 \ud150\uc11c \uc5f0\uc0b0\ub4e4\uc744\n`\uc5ec\uae30 <https://pytorch.org/docs/stable/torch.html>`__ \uc5d0\uc11c \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\uac01 \uc5f0\uc0b0\ub4e4\uc740 (\uc77c\ubc18\uc801\uc73c\ub85c CPU\ubcf4\ub2e4 \ube60\ub978) GPU\uc5d0\uc11c \uc2e4\ud589\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. Colab\uc744 \uc0ac\uc6a9\ud55c\ub2e4\uba74,\nEdit > Notebook Settings \uc5d0\uc11c GPU\ub97c \ud560\ub2f9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\uae30\ubcf8\uc801\uc73c\ub85c \ud150\uc11c\ub294 CPU\uc5d0 \uc0dd\uc131\ub429\ub2c8\ub2e4. ``.to`` \uba54\uc18c\ub4dc\ub97c \uc0ac\uc6a9\ud558\uba74 (GPU\uc758 \uac00\uc6a9\uc131(availability)\uc744 \ud655\uc778\ud55c \ub4a4)\nGPU\ub85c \ud150\uc11c\ub97c \uba85\uc2dc\uc801\uc73c\ub85c \uc774\ub3d9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc7a5\uce58\ub4e4 \uac04\uc5d0 \ud070 \ud150\uc11c\ub4e4\uc744 \ubcf5\uc0ac\ud558\ub294 \uac83\uc740 \uc2dc\uac04\uacfc \uba54\ubaa8\ub9ac \uce21\uba74\uc5d0\uc11c \ube44\uc6a9\uc774\n\ub9ce\uc774\ub4e0\ub2e4\ub294 \uac83\uc744 \uae30\uc5b5\ud558\uc138\uc694!\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# GPU\uac00 \uc874\uc7ac\ud558\uba74 \ud150\uc11c\ub97c \uc774\ub3d9\ud569\ub2c8\ub2e4\nif torch.cuda.is_available():\n    tensor = tensor.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ubaa9\ub85d\uc5d0\uc11c \uba87\uba87 \uc5f0\uc0b0\ub4e4\uc744 \uc2dc\ub3c4\ud574\ubcf4\uc138\uc694.\nNumPy API\uc5d0 \uc775\uc219\ud558\ub2e4\uba74 Tensor API\ub97c \uc0ac\uc6a9\ud558\ub294 \uac83\uc740 \uc2dd\uc740 \uc8fd \uba39\uae30\ub77c\ub294 \uac83\uc744 \uc54c\uac8c \ub418\uc2e4 \uac81\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**NumPy\uc2dd\uc758 \ud45c\uc900 \uc778\ub371\uc2f1\uacfc \uc2ac\ub77c\uc774\uc2f1:**\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tensor = torch.ones(4, 4)\nprint(f\"First row: {tensor[0]}\")\nprint(f\"First column: {tensor[:, 0]}\")\nprint(f\"Last column: {tensor[..., -1]}\")\ntensor[:,1] = 0\nprint(tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**\ud150\uc11c \ud569\uce58\uae30** ``torch.cat`` \uc744 \uc0ac\uc6a9\ud558\uc5ec \uc8fc\uc5b4\uc9c4 \ucc28\uc6d0\uc5d0 \ub530\ub77c \uc77c\ub828\uc758 \ud150\uc11c\ub97c \uc5f0\uacb0\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n``torch.cat`` \uacfc \ubbf8\ubb18\ud558\uac8c \ub2e4\ub978 \ub610 \ub2e4\ub978 \ud150\uc11c \uacb0\ud569 \uc5f0\uc0b0\uc778\n`torch.stack <https://pytorch.org/docs/stable/generated/torch.stack.html>`__ \ub3c4 \ucc38\uace0\ud574\ubcf4\uc138\uc694.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\nprint(t1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**\uc0b0\uc220 \uc5f0\uc0b0(Arithmetic operations)**\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \ub450 \ud150\uc11c \uac04\uc758 \ud589\ub82c \uacf1(matrix multiplication)\uc744 \uacc4\uc0b0\ud569\ub2c8\ub2e4. y1, y2, y3\uc740 \ubaa8\ub450 \uac19\uc740 \uac12\uc744 \uac16\uc2b5\ub2c8\ub2e4.\ny1 = tensor @ tensor.T\ny2 = tensor.matmul(tensor.T)\n\ny3 = torch.rand_like(tensor)\ntorch.matmul(tensor, tensor.T, out=y3)\n\n\n# \uc694\uc18c\ubcc4 \uacf1(element-wise product)\uc744 \uacc4\uc0b0\ud569\ub2c8\ub2e4. z1, z2, z3\ub294 \ubaa8\ub450 \uac19\uc740 \uac12\uc744 \uac16\uc2b5\ub2c8\ub2e4.\nz1 = tensor * tensor\nz2 = tensor.mul(tensor)\n\nz3 = torch.rand_like(tensor)\ntorch.mul(tensor, tensor, out=z3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**\ub2e8\uc77c-\uc694\uc18c(single-element) \ud150\uc11c** \ud150\uc11c\uc758 \ubaa8\ub4e0 \uac12\uc744 \ud558\ub098\ub85c \uc9d1\uacc4(aggregate)\ud558\uc5ec \uc694\uc18c\uac00 \ud558\ub098\uc778 \ud150\uc11c\uc758 \uacbd\uc6b0,\n``item()`` \uc744 \uc0ac\uc6a9\ud558\uc5ec Python \uc22b\uc790 \uac12\uc73c\ub85c \ubcc0\ud658\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "agg = tensor.sum()\nagg_item = agg.item()\nprint(agg_item, type(agg_item))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**\ubc14\uafd4\uce58\uae30(in-place) \uc5f0\uc0b0**\n\uc5f0\uc0b0 \uacb0\uacfc\ub97c \ud53c\uc5f0\uc0b0\uc790(operand)\uc5d0 \uc800\uc7a5\ud558\ub294 \uc5f0\uc0b0\uc744 \ubc14\uafd4\uce58\uae30 \uc5f0\uc0b0\uc774\ub77c\uace0 \ubd80\ub974\uba70, ``_`` \uc811\ubbf8\uc0ac\ub97c \uac16\uc2b5\ub2c8\ub2e4.\n\uc608\ub97c \ub4e4\uc5b4: ``x.copy_(y)`` \ub098 ``x.t_()`` \ub294 ``x`` \ub97c \ubcc0\uacbd\ud569\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(f\"{tensor} \\n\")\ntensor.add_(5)\nprint(tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>\ubc14\uafd4\uce58\uae30 \uc5f0\uc0b0\uc740 \uba54\ubaa8\ub9ac\ub97c \uc77c\ubd80 \uc808\uc57d\ud558\uc9c0\ub9cc, \uae30\ub85d(history)\uc774 \uc989\uc2dc \uc0ad\uc81c\ub418\uc5b4 \ub3c4\ud568\uc218(derivative) \uacc4\uc0b0\uc5d0 \ubb38\uc81c\uac00 \ubc1c\uc0dd\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n     \ub530\ub77c\uc11c, \uc0ac\uc6a9\uc744 \uad8c\uc7a5\ud558\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--------------\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nNumPy \ubcc0\ud658(Bridge)\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nCPU \uc0c1\uc758 \ud150\uc11c\uc640 NumPy \ubc30\uc5f4\uc740 \uba54\ubaa8\ub9ac \uacf5\uac04\uc744 \uacf5\uc720\ud558\uae30 \ub54c\ubb38\uc5d0, \ud558\ub098\ub97c \ubcc0\uacbd\ud558\uba74 \ub2e4\ub978 \ud558\ub098\ub3c4 \ubcc0\uacbd\ub429\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud150\uc11c\ub97c NumPy \ubc30\uc5f4\ub85c \ubcc0\ud658\ud558\uae30\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "t = torch.ones(5)\nprint(f\"t: {t}\")\nn = t.numpy()\nprint(f\"n: {n}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud150\uc11c\uc758 \ubcc0\uacbd \uc0ac\ud56d\uc774 NumPy \ubc30\uc5f4\uc5d0 \ubc18\uc601\ub429\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "t.add_(1)\nprint(f\"t: {t}\")\nprint(f\"n: {n}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NumPy \ubc30\uc5f4\uc744 \ud150\uc11c\ub85c \ubcc0\ud658\ud558\uae30\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n = np.ones(5)\nt = torch.from_numpy(n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NumPy \ubc30\uc5f4\uc758 \ubcc0\uacbd \uc0ac\ud56d\uc774 \ud150\uc11c\uc5d0 \ubc18\uc601\ub429\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "np.add(n, 1, out=n)\nprint(f\"t: {t}\")\nprint(f\"n: {n}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}