{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Detection vs Recognition vs Tracking\n",
    "<hr>\n",
    "\n",
    "- 차이점\n",
    "    - 검출(Detection): 영상에서 찾고자 하는 대상의 위치와 크기를 알아내는 작업\n",
    "    - 인식(Recognition): 주어진 영상(객체)이 무엇인지 판별하는 작업(Classification, Identification)\n",
    "    - 추적(Tracking): 동영상에서 이전 프레임에 있던 특정 대상의 현재 프레임에서의 위치 변화를 알아내는 작업\n",
    "        - e.g., Mean Shift, CamShift, Optical flow, Trackers in OpenCV 3.x\n",
    "    - 만약 사람의 얼굴이 포함된 영상에서 누구인지는 상관없이 `모든 얼굴을 찾는 것을 검출`, 그 중 `특정 인물을 찾는 것을 인식`,<br> 동영상이나 여러 장의 영상에서 `특정 대상의 변화를 찾는 것이 추적`이다.\n",
    "- extra: Tracing vs Tracking\n",
    "    - to Trace: 이미 주어진 경로(객체의 외곽선 등)의 자취를 쫒아가며 그 대상의 위치와 형태를 알아내는 작업\n",
    "    - to Track: 동영상에서 특정 대상의 변화를 뒤쫒으며 추적하여 변화 과정을 알아내는 작업\n",
    "    - 만약 철수가 `내 과자를 허락없이 먹은 것을 목격하여` 철수를 잡아 따지기 위해 철수의 뒤를 쫒아가는 것을 `Tracking`,<br>\n",
    "    `누군가 내 과자를 허락없이 먹었는데` 주변에 과자 부스러기가 떨어져있고, 그 부스러기의 자취를 쫒아가봤더니 철수의 입가에<br>\n",
    "    내 과자로 추정되는 과자 부스러기가 묻어 있는 것을 발견하여 철수에게 따지러 가는 것이 `Tracing`이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = \"#CC3D3D\">Case #1: Background Subtraction</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Step #1: Concept\n",
    "<hr>\n",
    "\n",
    "- 배경 차분(Background Subtraction: BS)\n",
    "    - 등록된 배경 모델과 현재 입력 프레임과의 차영상을 이용하여 전경 객체를 검출하는 기법이다.\n",
    "    - 움직이는 전경 객체 검출을 위한 기본적인 방법이다.\n",
    "    - <img src=\"images/markdown/.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Step #2: Static Background Subtraction\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video open succeed!\n"
     ]
    }
   ],
   "source": [
    "# 정적 배경을 이용한 전경 객체 검출 예제\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "\n",
    "capture = cv2.VideoCapture(\"videos/PETS2000.avi\")\n",
    "\n",
    "if not capture.isOpened():\n",
    "    print(\"Video open failed!\")\n",
    "    sys.exit()\n",
    "else:\n",
    "    print(\"Video open succeed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background image registration succeed!\n"
     ]
    }
   ],
   "source": [
    "# 첫 번째 프레임을 배경 영상으로 등록\n",
    "retval, background = capture.read()\n",
    "\n",
    "if not retval:\n",
    "    print(\"Background image registration failed!\")\n",
    "    sys.exit()\n",
    "else:\n",
    "    print(\"Background image registration succeed!\")\n",
    "\n",
    "# 컬러 값이 반드시 필요한 상황이 아니고, 연산 속도를 증가시키기 위해 그레이스케일로 변환\n",
    "background_gray = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)\n",
    "background_gray = cv2.GaussianBlur(background_gray, (0, 0), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video was interrupted!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 비디오 매 프레임 처리\n",
    "while True:\n",
    "    retval, frame = capture.read()\n",
    "    \n",
    "    if not retval:\n",
    "        break\n",
    "    \n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame_gray = cv2.GaussianBlur(frame_gray, (0, 0), 1)\n",
    "    \n",
    "    # 차영상 구하기 & 이진화\n",
    "    difference = cv2.absdiff(background_gray, frame_gray)\n",
    "    _, difference = cv2.threshold(difference, 30, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # 레이블링 기법을 이용하여 원본 프레임에 바운딩 박스 표시\n",
    "    count, _, stats, _ = cv2.connectedComponentsWithStats(difference)\n",
    "    \n",
    "    for i in range(1, count):\n",
    "        x, y, w, h, s = stats[i]\n",
    "        \n",
    "        if s < 100:\n",
    "            continue\n",
    "        \n",
    "        cv2.rectangle(frame, (x, y, w, h), (0, 0, 255), 2)\n",
    "    \n",
    "    # OpenCV 가상 윈도우로 출력\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.imshow(\"Difference\", difference)\n",
    "\n",
    "    if cv2.waitKey(30) == 27:\n",
    "        print(\"Video was interrupted!\")\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Step #3: Moving Average Background Subtraction\n",
    "<hr>\n",
    "\n",
    "- 정적 배경 모델 사용 시 문제점\n",
    "    - 미리 등록된 디준 영상이 실제 배경과 크게 달라질 경우 오동작을 일으킬 수 있다.\n",
    "        - e.g., 그림자 등의 영향으로 인한 `조도 변경`, 시점 변경으로 인한 `밝기 감소`, `새로운 객체가 화면에 고정`되는 경우\n",
    "        - <img src=\"images/markdown/.png\" width=\"600\">\n",
    "\n",
    "<hr>\n",
    "\n",
    "- 평균 연산에 의한 배경 영상 생성\n",
    "    - 움직이는 객체가 존재하는 수백 장의 입력 영상으로부터 `평균 영상`을 구한다.\n",
    "    - <img src=\"images/markdown/.png\" width=\"600\">\n",
    "    - 다만 수백 장의 이전 프레임을 버퍼에 저장하려면 `대용량 메모리가 필요`하다.\n",
    "\n",
    "<hr>\n",
    "\n",
    "- 이동 평균(Moving Average)\n",
    "    - 수백 장의 영상을 저장하는 대신 `매 프레임이 들어올 때마다 평균 영상을 갱신`한다.\n",
    "    - 평균 연산에 비해 대용량 버퍼 메모리가 필요하지 않다.\n",
    "    - 내부 연산은 `cv2.addWeighted()` 함수와 같은 `가중치 합`을 구하는 형태이며, 이전 프레임까지의 `배경 영상`과 `현재 프레임`의<br>\n",
    "    `가중치 합`을 계산하여 현재 프레임에서의 `배경 영상`을 업데이트 하는 방법이다.\n",
    "\n",
    "$$B(x,y,t)=\\alpha\\cdot I(x,y,t)+(1-\\alpha)\\cdot B(x,y,t-1)$$\n",
    "$$B(x,y,t)={\\scriptstyle\\text{갱신된 배경 영상}}$$\n",
    "$$\\alpha={\\scriptstyle\\text{현재 프레임에 대한 가중치}},\\ (0<\\alpha<1)$$\n",
    "$$I(x,y,t)={\\scriptstyle\\text{현재 프레임}}$$\n",
    "$$B(x,y,t-1)={\\scriptstyle\\text{이전 프레임까지의 배경 영상}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Step #3-1: OpenCV function\n",
    "<hr>\n",
    "\n",
    "> `이동 평균 계산을 위한 가중치 누적 함수`\n",
    "\n",
    "$$\\mathsf{{\\color{RoyalBlue}cv2.}{\\color{Tan}accumulateWeighted}(src, dst, alpha, mask)\\rightarrow }$$\n",
    "- src: 입력 영상\n",
    "- dst: 축적 영상(결과 영상)\n",
    "- alpha: (입력 영상에 대한) 가중치\n",
    "- mask: 마스크 연산 시 사용할 마스크 영상\n",
    "- `참고사항:`\n",
    "    - src: 1 or 3 channel, 8 bit or 32 bit float type\n",
    "    - dst: src와 동일 채널, 32 bit or 64 bit float type\n",
    "    - alpha: `1을 지정`하면 이전까지의 배경 영상을 무시하고 `현재 프레임을 배경 영상으로 사용`한다.<br>\n",
    "    반대로 `0을 지정`하면 현재 프레임에 대한 정보가 사라지고 처음에 모델로 사용한 배경 영상을 계속 사용한다.`(정적 배경 모델)`\n",
    "        - 일반적으로 `0에 가까운 값`을 지정한다.`(e.g., alpha = 0.01 or less)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Step #3-2: Implementation example\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video open succeed!\n"
     ]
    }
   ],
   "source": [
    "# 이동 평균에 의한 배경 차분 예제\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "capture = cv2.VideoCapture(\"videos/PETS2000.avi\")\n",
    "\n",
    "if not capture.isOpened():\n",
    "    print(\"Video open failed!\")\n",
    "    sys.exit()\n",
    "else:\n",
    "    print(\"Video open succeed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background image registration succeed!\n"
     ]
    }
   ],
   "source": [
    "# 첫 번째 프레임을 배경 영상으로 등록\n",
    "retval, background = capture.read()\n",
    "\n",
    "if not retval:\n",
    "    print(\"Background image registration failed!\")\n",
    "    sys.exit()\n",
    "else:\n",
    "    print(\"Background image registration succeed!\")\n",
    "\n",
    "# background: uint8 배경, background_float: float32 배경\n",
    "background = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)\n",
    "background = cv2.GaussianBlur(background, (0, 0), 1)\n",
    "background_float = background.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video was interrupted!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 비디오 매 프레임 처리\n",
    "while True:\n",
    "    retval, frame = capture.read()\n",
    "    \n",
    "    if not retval:\n",
    "        break\n",
    "    \n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame_gray = cv2.GaussianBlur(frame_gray, (0, 0), 1)\n",
    "    \n",
    "    # background_float: 이전 프레임까지의 배경(float32), background: 갱신된 배경(uint8)\n",
    "    cv2.accumulateWeighted(frame_gray, background_float, 0.01)\n",
    "    background = background_float.astype(np.uint8)\n",
    "        \n",
    "    # 차영상 구하기 & 이진화\n",
    "    difference = cv2.absdiff(background, frame_gray)\n",
    "    _, difference = cv2.threshold(difference, 30, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # 레이블링 기법을 이용한 원본 프레임의 움직이는 객체에 바운딩 박스 표시\n",
    "    count, _, stats, _ = cv2.connectedComponentsWithStats(difference)\n",
    "    \n",
    "    for i in range(1, count):\n",
    "        x, y, w, h, s = stats[i]\n",
    "        \n",
    "        if s < 100:\n",
    "            continue\n",
    "        \n",
    "        cv2.rectangle(frame, (x, y, w, h), (0, 0, 255), 2)\n",
    "    \n",
    "    # OpenCV 가상 윈도우로 출력\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.imshow(\"Difference\", difference)\n",
    "    cv2.imshow(\"Background\", background)\n",
    "\n",
    "    if cv2.waitKey(30) == 27:\n",
    "        print(\"Video was interrupted!\")\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Step #4: MOG Background Model\n",
    "<hr>\n",
    "\n",
    "- MOG\n",
    "    - Mixture of Gaussian, GMM(Gaussian Mixture Model)\n",
    "    - 각 픽셀에 대해 MOG 확률 모델을 설정하여 배경과 전경을 구분하는 일종의 데이터 분석 기법이다.\n",
    "\n",
    "<hr>\n",
    "\n",
    "- 다양한 배경 모델 구성 방법\n",
    "    - <img src=\"images/markdown/.png\" width=\"600\">\n",
    "\n",
    "<hr>\n",
    "\n",
    "- dfdfdfd\n",
    "    - <img src=\"images/markdown/.png\" width=\"600\">\n",
    "\n",
    "<hr>\n",
    "\n",
    "- dfdfdf\n",
    "    - <img src=\"images/markdown/.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Step #4-1: OpenCV function\n",
    "<hr>\n",
    "\n",
    "> `배경 차분 알고리즘 객체 생성`\n",
    "\n",
    "$$\\mathsf{{\\color{RoyalBlue}cv2.}{\\color{Tan}createBackgroundSubtractorMOG2}(, history, varThreshold, detectShadows)\\rightarrow retval}$$\n",
    "- history: 히스토리 길이\n",
    "- varThreshold: variance threshold. 픽셀과 모델 사이의 마할라노비스 거리(Mahalanobis distance) 제곱에 대한 임계값\n",
    "- detectShadows: 그림자 검출 여부\n",
    "- retval: cv2.BackgroundSubtractor 클래스 인스턴스(객체)\n",
    "- `참고사항:`\n",
    "    - history: 이전(과거) 프레임을 몇 개까지 사용할지를 지정한다.\n",
    "        - `기본값은 500`\n",
    "    - varThreshold: 해당 픽셀이 배경 모델에 의해 잘 표현되는 지를 판단한다. 이 파라미터는 배경 영상 갱신에 영향을 주지 않는다.\n",
    "        - `기본값은 16`\n",
    "    - detectShadows: `기본값은 True`\n",
    "\n",
    "$$\\mathsf{{\\color{RoyalBlue}cv2.}{\\color{Tan}createBackgroundSubtractorKNN}(, history, dist2Threshold, detectShadows)\\rightarrow }$$\n",
    "- history: \n",
    "- dist2Threshold: distance to threshold. 픽셀과 샘플 사이의 거리 제곱에 대한 임계값\n",
    "- detectShadows: \n",
    "- retval: cv2.BackgroundSubtractor 클래스 인스턴스(객체)\n",
    "- `참고사항:`\n",
    "    - history: 이전(과거) 프레임을 몇 개까지 사용할지를 지정한다.\n",
    "        - `기본값은 500`\n",
    "    - dist2Threshold: 해당 픽셀이 샘플에 가까운 지를 판단한다. 이 파라미터는 배경 영상 갱신에 영향을 주지 않는다.\n",
    "        - `기본값은 400`\n",
    "    - detectShadows: `기본값은 True`\n",
    "\n",
    "<hr>\n",
    "\n",
    "> `전경 객체 마스크 생성 함수`\n",
    "\n",
    "$$\\mathsf{{\\color{RoyalBlue}cv2.BackgroundSubtractor.}{\\color{Tan}apply}(image, fgmask, learningRate)\\rightarrow fgmask}$$\n",
    "- image: (입력) 다음 비디로 프레임\n",
    "- fgmask: foreground mask. (출력) 전경 마스크 영상\n",
    "- learningRate: 배경 모델 학습율(속도) 지정\n",
    "- `참고사항:`\n",
    "    - fgmask: 8 bit 이진 영상(0 or 255). `detectShadows = True`이면 `0 or 128 or 255`로 이루어진 영상을 반환한다.\n",
    "    - learningRate: 0 ~ 1 사이의 실수를 지정한다. `이동 평균의 가중치(alpha)`와 같은 역할이다.\n",
    "        - 0: 배경 모델을 갱신하지 않음\n",
    "        - 1: 매 프레임마다 배경 모델을 새로 만듦\n",
    "        - -1: 자동으로 결정됨. `기본값`\n",
    "\n",
    "<hr>\n",
    "\n",
    "> `배경 영상 반환 함수`\n",
    "\n",
    "$$\\mathsf{{\\color{RoyalBlue}cv2.BackgroundSubtractor.}{\\color{Tan}getBackgroundImage}(, backgroundImage)\\rightarrow backgroundImage}$$\n",
    "- backgroundImage: (출력) 학습된 배경 영상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "help(cv2.BackgroundSubtractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "help(cv2.createBackgroundSubtractorMOG2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "help(cv2.createBackgroundSubtractorKNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "help(cv2.BackgroundSubtractor.apply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "help(cv2.BackgroundSubtractor.getBackgroundImage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Step #4-2: Implementation example\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video open succeed!\n"
     ]
    }
   ],
   "source": [
    "# MOG 기법을 이용한 배경 생성 및 전경 객체 검출 예제\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "capture = cv2.VideoCapture(\"videos/PETS2000.avi\")\n",
    "\n",
    "if not capture.isOpened():\n",
    "    print(\"Video open failed!\")\n",
    "    sys.exit()\n",
    "else:\n",
    "    print(\"Video open succeed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배경 차분 알고리즘 객체 생성\n",
    "# BS = cv2.createBackgroundSubtractorMOG2()\n",
    "BS = cv2.createBackgroundSubtractorKNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 비디오 매 프레임 처리\n",
    "while True:\n",
    "    retval, frame = capture.read()\n",
    "    \n",
    "    if not retval:\n",
    "        break\n",
    "    \n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    fgmask = BS.apply(frame_gray)\n",
    "    background = BS.getBackgroundImage()\n",
    "    \n",
    "    # 레이블링 기법을 이용하여 바운딩 박스 표시\n",
    "    count, _, stats, _ = cv2.connectedComponentsWithStats(fgmask)\n",
    "    \n",
    "    for i in range(1, count):\n",
    "        x, y, w, h, s = stats[i]\n",
    "        \n",
    "        if s < 100:\n",
    "            continue\n",
    "        \n",
    "        cv2.rectangle(frame, (x, y, w, h), (0, 0, 255), 2)\n",
    "    \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.imshow(\"Difference\", fgmask)\n",
    "    cv2.imshow(\"Background\", background)\n",
    "    \n",
    "    if cv2.waitKey(30) == 27:\n",
    "        print(\"Video was interrupted!\")\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = \"#CC3D3D\">Case #2: Mean Shift Algorithm</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Step #1: Concept\n",
    "<hr>\n",
    "\n",
    "- 평균 이동(Mean Shift)\n",
    "    - 평균 이동이라고 하는 것은 데이터사이언스 분야에서 `어떤 데이터의 분포를 분석하는 기법 중 하나`이고, 어떤 데이터의 분포에서<br>\n",
    "    `데이터가 가장 밀집되어 있는 부분`을 찾아내기 위한 기법이다.\n",
    "        - e.g., 어떤 데이터가 가우시안 분포 형태를 이루고 있을 때 그 `가우시안 분포의 평균(mode)`를 찾아내는 방법이다.<br>\n",
    "        경우에 따라서 `모드 검출(mode seeking) 알고리즘`이라는 용어로도 사용한다.\n",
    "    - 평균 이동 알고리즘은 국지적 평균(Local Mean)을 탐색하면서 이동한다.\n",
    "\n",
    "<hr>\n",
    "\n",
    "- 평균 이동 알고리즘 작동 예시\n",
    "    - <img src=\"images/markdown/MeanShift/MeanShifted1.png\" width=\"200\">\n",
    "    - <img src=\"images/markdown/MeanShift/MeanShifted2.png\" width=\"200\">\n",
    "    - <img src=\"images/markdown/MeanShift/MeanShifted3.png\" width=\"200\">\n",
    "    - <img src=\"images/markdown/MeanShift/MeanShifted4.png\" width=\"200\">\n",
    "    - <img src=\"images/markdown/MeanShift/MeanShifted5.png\" width=\"200\">\n",
    "    - <img src=\"images/markdown/MeanShift/MeanShifted6.png\" width=\"200\">\n",
    "    - <img src=\"images/markdown/MeanShift/MeanShifted7.png\" width=\"200\">\n",
    "    - <img src=\"images/markdown/MeanShift/MeanShifted8.png\" width=\"200\">\n",
    "    - <img src=\"images/markdown/MeanShift/MeanShifted9.png\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Step #2: OpenCV function\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Step #3: Implementation example\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$$\\mathsf{{\\color{RoyalBlue} }{\\color{Tan} }()\\rightarrow }$$\n",
    "- <img src=\"images/markdown/.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = \"#CC3D3D\">Case #3: CamShift Algorithm</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Step #1: Concept\n",
    "<hr>\n",
    "\n",
    "- 캠시프트(CamShift)\n",
    "    - 연속 적응 평균 이동(Continuously Adaptive Mean Shift)의 약자이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Step #2: OpenCV function\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Step #3: Implementation example\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = \"#CC3D3D\">Case #4: Optical flow</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Step #1: Concept\n",
    "<hr>\n",
    "\n",
    "- 옵티컬플로우(Optical flow)\n",
    "    - dfdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Step #2: OpenCV function\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Step #3: Implementation example\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = \"#CC3D3D\">Case #5: OpenCV Tracker</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Step #1: Concept\n",
    "<hr>\n",
    "\n",
    "- OpenCV 트래커(OpenCV Tracker)\n",
    "    - dfdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Step #2: OpenCV function\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Step #3: Implementation example\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38cc0cca68228d4d18227abe74ed813685db17db46984279e4aabdddebf5f1ba"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
