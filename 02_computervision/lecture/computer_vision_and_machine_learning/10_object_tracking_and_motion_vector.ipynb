{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = \"#CC3D3D\">Case #1: Background Subtraction</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Step #1: Concept\n",
    "<hr>\n",
    "\n",
    "- 배경 차분(Background Subtraction: BS)\n",
    "    - 등록된 배경 모델과 현재 입력 프레임과의 차영상을 이용하여 전경 객체를 검출하는 기법이다.\n",
    "    - 움직이는 전경 객체 검출을 위한 기본적인 방법이다.\n",
    "    - <img src=\"images/markdown/.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Step #2: Static Background Subtraction\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video open succeed!\n"
     ]
    }
   ],
   "source": [
    "# 정적 배경을 이용한 전경 객체 검출 예제\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "\n",
    "capture = cv2.VideoCapture(\"videos/PETS2000.avi\")\n",
    "\n",
    "if not capture.isOpened():\n",
    "    print(\"Video open failed!\")\n",
    "    sys.exit()\n",
    "else:\n",
    "    print(\"Video open succeed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background image registration succeed!\n"
     ]
    }
   ],
   "source": [
    "# 첫 번째 프레임을 배경 영상으로 등록\n",
    "retval, background = capture.read()\n",
    "\n",
    "if not retval:\n",
    "    print(\"Background image registration failed!\")\n",
    "    sys.exit()\n",
    "else:\n",
    "    print(\"Background image registration succeed!\")\n",
    "\n",
    "# 컬러 값이 반드시 필요한 상황이 아니고, 연산 속도를 증가시키기 위해 그레이스케일로 변환\n",
    "background_gray = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)\n",
    "background_gray = cv2.GaussianBlur(background_gray, (0, 0), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video was interrupted!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 비디오 매 프레임 처리\n",
    "while True:\n",
    "    retval, frame = capture.read()\n",
    "    \n",
    "    if not retval:\n",
    "        break\n",
    "    \n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame_gray = cv2.GaussianBlur(frame_gray, (0, 0), 1)\n",
    "    \n",
    "    # 차영상 구하기 & 이진화\n",
    "    difference = cv2.absdiff(background_gray, frame_gray)\n",
    "    _, difference = cv2.threshold(difference, 30, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # 레이블링 기법을 이용하여 원본 프레임에 바운딩 박스 표시\n",
    "    count, _, stats, _ = cv2.connectedComponentsWithStats(difference)\n",
    "    \n",
    "    for i in range(1, count):\n",
    "        x, y, w, h, s = stats[i]\n",
    "        \n",
    "        if s < 100:\n",
    "            continue\n",
    "        \n",
    "        cv2.rectangle(frame, (x, y, w, h), (0, 0, 255), 2)\n",
    "    \n",
    "    # OpenCV 가상 윈도우로 출력\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.imshow(\"Difference\", difference)\n",
    "\n",
    "    if cv2.waitKey(30) == 27:\n",
    "        print(\"Video was interrupted!\")\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Step #3: Moving Average Background Subtraction\n",
    "<hr>\n",
    "\n",
    "- 정적 배경 모델 사용 시 문제점\n",
    "    - 미리 등록된 디준 영상이 실제 배경과 크게 달라질 경우 오동작을 일으킬 수 있다.\n",
    "        - e.g., 그림자 등의 영향으로 인한 `조도 변경`, 시점 변경으로 인한 `밝기 감소`, `새로운 객체가 화면에 고정`되는 경우\n",
    "        - <img src=\"images/markdown/.png\" width=\"600\">\n",
    "\n",
    "<hr>\n",
    "\n",
    "- 평균 연산에 의한 배경 영상 생성\n",
    "    - 움직이는 객체가 존재하는 수백 장의 입력 영상으로부터 `평균 영상`을 구한다.\n",
    "    - <img src=\"images/markdown/.png\" width=\"600\">\n",
    "    - 다만 수백 장의 이전 프레임을 버퍼에 저장하려면 `대용량 메모리가 필요`하다.\n",
    "\n",
    "<hr>\n",
    "\n",
    "- 이동 평균(Moving Average)\n",
    "    - 수백 장의 영상을 저장하는 대신 `매 프레임이 들어올 때마다 평균 영상을 갱신`한다.\n",
    "    - 평균 연산에 비해 대용량 버퍼 메모리가 필요하지 않다.\n",
    "    - 내부 연산은 `cv2.addWeighted()` 함수와 같은 `가중치 합`을 구하는 형태이며, 이전 프레임까지의 `배경 영상`과 `현재 프레임`의<br>\n",
    "    `가중치 합`을 계산하여 현재 프레임에서의 `배경 영상`을 업데이트 하는 방법이다.\n",
    "\n",
    "$$B(x,y,t)=\\alpha\\cdot I(x,y,t)+(1-\\alpha)\\cdot B(x,y,t-1)$$\n",
    "$$B(x,y,t)={\\scriptstyle\\text{갱신된 배경 영상}}$$\n",
    "$$\\alpha={\\scriptstyle\\text{현재 프레임에 대한 가중치}},\\ (0<\\alpha<1)$$\n",
    "$$I(x,y,t)={\\scriptstyle\\text{현재 프레임}}$$\n",
    "$$B(x,y,t-1)={\\scriptstyle\\text{이전 프레임까지의 배경 영상}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Step #3-1: OpenCV function\n",
    "<hr>\n",
    "\n",
    "> `이동 평균 계산을 위한 가중치 누적 함수`\n",
    "\n",
    "$$\\mathsf{{\\color{RoyalBlue}cv2.}{\\color{Tan}accumulateWeighted}(src, dst, alpha, mask)\\rightarrow }$$\n",
    "- src: 입력 영상\n",
    "- dst: 축적 영상(결과 영상)\n",
    "- alpha: (입력 영상에 대한) 가중치\n",
    "- mask: 마스크 연산 시 사용할 마스크 영상\n",
    "- `참고사항:`\n",
    "    - src: 1 or 3 channel, 8 bit or 32 bit float type\n",
    "    - dst: src와 동일 채널, 32 bit or 64 bit float type\n",
    "    - alpha: `1을 지정`하면 이전까지의 배경 영상을 무시하고 `현재 프레임을 배경 영상으로 사용`한다.<br>\n",
    "    반대로 `0을 지정`하면 현재 프레임에 대한 정보가 사라지고 처음에 모델로 사용한 배경 영상을 계속 사용한다.`(정적 배경 모델)`\n",
    "        - 일반적으로 `0에 가까운 값`을 지정한다.`(e.g., alpha = 0.01 or less)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Step #3-2: Implementation example\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video open succeed!\n"
     ]
    }
   ],
   "source": [
    "# 이동 평균에 의한 배경 차분 예제\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "capture = cv2.VideoCapture(\"videos/PETS2000.avi\")\n",
    "\n",
    "if not capture.isOpened():\n",
    "    print(\"Video open failed!\")\n",
    "    sys.exit()\n",
    "else:\n",
    "    print(\"Video open succeed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background image registration succeed!\n"
     ]
    }
   ],
   "source": [
    "# 첫 번째 프레임을 배경 영상으로 등록\n",
    "retval, background = capture.read()\n",
    "\n",
    "if not retval:\n",
    "    print(\"Background image registration failed!\")\n",
    "    sys.exit()\n",
    "else:\n",
    "    print(\"Background image registration succeed!\")\n",
    "\n",
    "# background: uint8 배경, background_float: float32 배경\n",
    "background = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)\n",
    "background = cv2.GaussianBlur(background, (0, 0), 1)\n",
    "background_float = background.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video was interrupted!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 비디오 매 프레임 처리\n",
    "while True:\n",
    "    retval, frame = capture.read()\n",
    "    \n",
    "    if not retval:\n",
    "        break\n",
    "    \n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame_gray = cv2.GaussianBlur(frame_gray, (0, 0), 1)\n",
    "    \n",
    "    # background_float: 이전 프레임까지의 배경(float32), background: 갱신된 배경(uint8)\n",
    "    cv2.accumulateWeighted(frame_gray, background_float, 0.01)\n",
    "    background = background_float.astype(np.uint8)\n",
    "        \n",
    "    # 차영상 구하기 & 이진화\n",
    "    difference = cv2.absdiff(background, frame_gray)\n",
    "    _, difference = cv2.threshold(difference, 30, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # 레이블링 기법을 이용한 원본 프레임의 움직이는 객체에 바운딩 박스 표시\n",
    "    count, _, stats, _ = cv2.connectedComponentsWithStats(difference)\n",
    "    \n",
    "    for i in range(1, count):\n",
    "        x, y, w, h, s = stats[i]\n",
    "        \n",
    "        if s < 100:\n",
    "            continue\n",
    "        \n",
    "        cv2.rectangle(frame, (x, y, w, h), (0, 0, 255), 2)\n",
    "    \n",
    "    # OpenCV 가상 윈도우로 출력\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.imshow(\"Difference\", difference)\n",
    "    cv2.imshow(\"Background\", background)\n",
    "\n",
    "    if cv2.waitKey(30) == 27:\n",
    "        print(\"Video was interrupted!\")\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Step #4: MOG Background Model\n",
    "<hr>\n",
    "\n",
    "- MOG\n",
    "    - Mixture of Gaussian, GMM(Gaussian Mixture Model)\n",
    "    - 각 픽셀에 대해 MOG 확률 모델을 설정하여 배경과 전경을 구분하는 일종의 데이터 분석 기법이다.\n",
    "\n",
    "<hr>\n",
    "\n",
    "- 다양한 배경 모델 구성 방법\n",
    "    - <img src=\"images/markdown/.png\" width=\"600\">\n",
    "\n",
    "<hr>\n",
    "\n",
    "- dfdfdfd\n",
    "    - <img src=\"images/markdown/.png\" width=\"600\">\n",
    "\n",
    "<hr>\n",
    "\n",
    "- dfdfdf\n",
    "    - <img src=\"images/markdown/.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Step #4-1: OpenCV function\n",
    "<hr>\n",
    "\n",
    "> `배경 차분 모델 객체 생성`\n",
    "\n",
    "$$\\mathsf{{\\color{RoyalBlue}cv2.}{\\color{Tan}createBackgroundSubtractorMOG2}(, history, varThreshold, detectShadows)\\rightarrow retval}$$\n",
    "- history: 히스토리 길이\n",
    "- varThreshold: variance threshold. 픽셀과 모델 사이의 마할라노비스 거리(Mahalanobis distance) 제곱에 대한 임계값\n",
    "- detectShadows: 그림자 검출 여부\n",
    "- retval: cv2.BackgroundSubtractor 클래스 인스턴스(객체)\n",
    "- `참고사항:`\n",
    "    - history: 이전(과거) 프레임을 몇 개까지 사용할지를 지정한다.\n",
    "        - `기본값은 500`\n",
    "    - varThreshold: 해당 픽셀이 배경 모델에 의해 잘 표현되는 지를 판단한다. 이 파라미터는 배경 영상 갱신에 영향을 주지 않는다.\n",
    "        - `기본값은 16`\n",
    "    - detectShadows: `기본값은 True`\n",
    "\n",
    "$$\\mathsf{{\\color{RoyalBlue}cv2.}{\\color{Tan}createBackgroundSubtractorKNN}(, history, dist2Threshold, detectShadows)\\rightarrow }$$\n",
    "- history: \n",
    "- dist2Threshold: distance to threshold. 픽셀과 샘플 사이의 거리 제곱에 대한 임계값\n",
    "- detectShadows: \n",
    "- retval: cv2.BackgroundSubtractor 클래스 인스턴스(객체)\n",
    "- `참고사항:`\n",
    "    - history: 이전(과거) 프레임을 몇 개까지 사용할지를 지정한다.\n",
    "        - `기본값은 500`\n",
    "    - dist2Threshold: 해당 픽셀이 샘플에 가까운 지를 판단한다. 이 파라미터는 배경 영상 갱신에 영향을 주지 않는다.\n",
    "        - `기본값은 400`\n",
    "    - detectShadows: `기본값은 True`\n",
    "\n",
    "<hr>\n",
    "\n",
    "> `전경 객체 마스크 생성 함수`\n",
    "\n",
    "$$\\mathsf{{\\color{RoyalBlue} }{\\color{Tan} }()\\rightarrow }$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Step #4-2: Implementation example\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(cv2.createBackgroundSubtractorMOG2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(cv2.createBackgroundSubtractorKNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = \"#CC3D3D\">Case #2: Background Subtraction</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$$\\mathsf{{\\color{RoyalBlue} }{\\color{Tan} }()\\rightarrow }$$\n",
    "- <img src=\"images/markdown/.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Tracing vs Tracking\n",
    "<hr>\n",
    "\n",
    "- To trace: follow the completed path backwards from it's current point to where it began.\n",
    "\n",
    "- To track: follow the emerging path forwards from your starting point to wherever<br>\n",
    "the thing currently is."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38cc0cca68228d4d18227abe74ed813685db17db46984279e4aabdddebf5f1ba"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
