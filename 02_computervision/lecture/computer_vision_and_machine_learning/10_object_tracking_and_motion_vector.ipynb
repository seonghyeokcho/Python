{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = \"#CC3D3D\">Case #1: Background Subtraction</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Step #1: Concept\n",
    "<hr>\n",
    "\n",
    "- 배경 차분(Background Subtraction: BS)\n",
    "    - 등록된 배경 모델과 현재 입력 프레임과의 차영상을 이용하여 전경 객체를 검출하는 기법이다.\n",
    "    - 움직이는 전경 객체 검출을 위한 기본적인 방법이다.\n",
    "    - <img src=\"images/markdown/.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Step #2: Static Background Subtraction\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video open succeed!\n"
     ]
    }
   ],
   "source": [
    "# 정적 배경을 이용한 전경 객체 검출 예제\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "\n",
    "capture = cv2.VideoCapture(\"videos/PETS2000.avi\")\n",
    "\n",
    "if not capture.isOpened():\n",
    "    print(\"Video open failed!\")\n",
    "    sys.exit()\n",
    "else:\n",
    "    print(\"Video open succeed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background image registration succeed!\n"
     ]
    }
   ],
   "source": [
    "# 첫 번째 프레임을 배경으로 할당\n",
    "retval, background = capture.read()\n",
    "\n",
    "if not retval:\n",
    "    print(\"Background image registration failed!\")\n",
    "    sys.exit()\n",
    "else:\n",
    "    print(\"Background image registration succeed!\")\n",
    "\n",
    "# 컬러 값이 반드시 필요한 상황이 아니고, 연산 속도를 증가시키기 위해 그레이스케일로 변환\n",
    "background_gray = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)\n",
    "background_gray = cv2.GaussianBlur(background_gray, (0, 0), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video was interrupted!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 비디오 매 프레임 처리\n",
    "while True:\n",
    "    retval, frame = capture.read()\n",
    "    \n",
    "    if not retval:\n",
    "        break\n",
    "    \n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame_gray = cv2.GaussianBlur(frame_gray, (0, 0), 1)\n",
    "    \n",
    "    # 차영상 구하기 & 이진화\n",
    "    difference = cv2.absdiff(background_gray, frame_gray)\n",
    "    _, difference = cv2.threshold(difference, 30, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # 레이블링 기법을 이용하여 원본 프레임에 바운딩 박스 표시\n",
    "    count, _, stats, _ = cv2.connectedComponentsWithStats(difference)\n",
    "    \n",
    "    for i in range(1, count):\n",
    "        x, y, w, h, s = stats[i]\n",
    "        \n",
    "        if s < 100:\n",
    "            continue\n",
    "        \n",
    "        cv2.rectangle(frame, (x, y, w, h), (0, 0, 255), 2)\n",
    "    \n",
    "    # OpenCV 가상 윈도우로 출력\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.imshow(\"Difference\", difference)\n",
    "\n",
    "    if cv2.waitKey(30) == 27:\n",
    "        print(\"Video was interrupted!\")\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Step #3: Moving Average Background Subtraction\n",
    "<hr>\n",
    "\n",
    "- 정적 배경 모델 사용 시 문제점\n",
    "    - 미리 등록된 디준 영상이 실제 배경과 크게 달라질 경우 오동작을 일으킬 수 있다.\n",
    "        - e.g., 그림자 등의 영향으로 인한 `조도 변경`, 시점 변경으로 인한 `밝기 감소`, `새로운 객체가 화면에 고정`되는 경우\n",
    "        - <img src=\"images/markdown/.png\" width=\"600\">\n",
    "\n",
    "<hr>\n",
    "\n",
    "- 평균 연산에 의한 배경 영상 생성\n",
    "    - 움직이는 객체가 존재하는 수백 장의 입력 영상으로부터 `평균 영상`을 구한다.\n",
    "    - <img src=\"images/markdown/.png\" width=\"600\">\n",
    "    - 다만 수백 장의 이전 프레임을 버퍼에 저장하려면 `대용량 메모리가 필요`하다.\n",
    "\n",
    "<hr>\n",
    "\n",
    "- 이동 평균(Moving Average)\n",
    "    - 수백 장의 영상을 저장하는 대신 `매 프레임이 들어올 때마다 평균 영상을 갱신`한다.\n",
    "    - 평균 연산에 비해 대용량 버퍼 메모리가 필요하지 않다.\n",
    "    - 내부 연산은 `cv2.addWeighted()` 함수와 같은 `가중치 합`을 구하는 형태이며, 이전 프레임까지의 `배경 영상`과 `현재 프레임`의<br>\n",
    "    `가중치 합`을 계산하여 현재 프레임에서의 `배경 영상`을 업데이트 하는 방법이다.\n",
    "\n",
    "$$B(x,y,t)=\\alpha\\cdot I(x,y,t)+(1-\\alpha)\\cdot B(x,y,t-1)$$\n",
    "$$B(x,y,t)={\\scriptstyle\\text{갱신된 배경 영상}}$$\n",
    "$$\\alpha={\\scriptstyle\\text{현재 프레임에 대한 가중치}},\\ (0<\\alpha<1)$$\n",
    "$$I(x,y,t)={\\scriptstyle\\text{현재 프레임}}$$\n",
    "$$B(x,y,t-1)={\\scriptstyle\\text{이전 프레임까지의 배경 영상}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$$\\mathsf{{\\color{RoyalBlue} }{\\color{Tan} }()\\rightarrow }$$\n",
    "- <img src=\"images/markdown/.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Step #3-1: OpenCV function\n",
    "<hr>\n",
    "\n",
    "> ``\n",
    "\n",
    "$$\\mathsf{{\\color{RoyalBlue}cv2.}{\\color{Tan} }()\\rightarrow }$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Step #3-2: Implementation example\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이동 평균에 의한 배경 차분 예제\n",
    "import sys\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Tracing vs Tracking\n",
    "<hr>\n",
    "\n",
    "- To trace: follow the completed path backwards from it's current point to where it began.\n",
    "\n",
    "- To track: follow the emerging path forwards from your starting point to wherever<br>\n",
    "the thing currently is."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38cc0cca68228d4d18227abe74ed813685db17db46984279e4aabdddebf5f1ba"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
