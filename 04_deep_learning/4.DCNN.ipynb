{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 심층 컨볼루션 신경망(DCNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서플로 2.x의 ConvNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "=================================================================\n",
      "Total params: 320\n",
      "Trainable params: 320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with MaxPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "=================================================================\n",
      "Total params: 320\n",
      "Trainable params: 320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCNN의 예: LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서플로 2.x에서 LeNet 코드 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, optimizers\n",
    "\n",
    "%load_ext tensorboard\n",
    "# 로그 초기화\n",
    "#!rm -rf ./logs/\n",
    "\n",
    "# 신경망과 훈련\n",
    "epochs = 20\n",
    "batch_size = 128\n",
    "verbose = 1\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "validation_split = 0.9\n",
    "\n",
    "img_rows, img_cols = 28, 28  # 입력 이미지 차원\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "nb_classes = 10  # 출력의 개수 = 자리 수\n",
    "\n",
    "# convnet 정의\n",
    "def build(input_shape, classes):\n",
    "    model = models.Sequential()\n",
    "    # CONV => RELU => POOL\n",
    "    model.add(layers.Convolution2D(20, (5, 5), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    # CONV => RELU => POOL\n",
    "    model.add(layers.Convolution2D(50, (5, 5), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    # Flatten => RELU layers\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(500, activation='relu'))\n",
    "    # 소프트맥스 본류기\n",
    "    model.add(layers.Dense(classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 : 훈련과 테스트 집합 사이에 섞고 분할\n",
    "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()\n",
    "\n",
    "# 크기 조정\n",
    "X_train = X_train.reshape((60000, 28, 28, 1))\n",
    "X_test = X_test.reshape((10000, 28, 28, 1))\n",
    "\n",
    "# 정규화\n",
    "X_train, X_test = X_train/255.0, X_test/255.0\n",
    "\n",
    "# 형식 변환\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# 한 줄로 가능\n",
    "#X_train = (X_train.reshape((60000, 28, 28, 1))/255.0).astype('float32')\n",
    "#X_test = (X_test.reshape((10000, 28, 28, 1))/255.0).astype('float32')\n",
    "\n",
    "# 부류 벡터를 이진 부류 행렬로 변환\n",
    "y_train = tf.keras.utils.to_categorical(y_train, nb_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 24, 24, 20)        520       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 12, 12, 20)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 8, 8, 50)          25050     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 4, 4, 50)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 500)               400500    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                5010      \n",
      "=================================================================\n",
      "Total params: 431,080\n",
      "Trainable params: 431,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 최적화기와 모델 초기화\n",
    "model = build(input_shape=input_shape, classes=nb_classes)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서보드를 사용\n",
    "callbacks = [\n",
    "    # 텐서보드 로그를 './logs' 디렉터리에 작성\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 적합화\n",
    "history = model.fit(X_train, y_train,\n",
    "                   batch_size=batch_size, epochs=20,\n",
    "                   verbose=verbose, validation_split=validation_split,\n",
    "                   callbacks=callbacks)\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=verbose)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d5264072eb6506c5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d5264072eb6506c5\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.79"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 - 0.21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝으로 CIFAR-10 이미지 인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, optimizers\n",
    "%load_ext tensorboard\n",
    "# 로그 초기화\n",
    "#!rm -rf ./logs/\n",
    "\n",
    "# CIFAR-10은 3채널 32x32 픽셀의 6만개 이미지다.\n",
    "img_channels = 3\n",
    "img_rows = 32\n",
    "img_cols = 32\n",
    "\n",
    "# 상수\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 20\n",
    "CLASSES = 10\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "OPTIM = tf.keras.optimizers.RMSprop()\n",
    "\n",
    "# convnet 정의\n",
    "def build(input_shape, classes):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Convolution2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 68s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# 데이터 : 훈련과 테스트 집합 사이에 섞고 분할\n",
    "(X_train, y_train), (X_test, y_test) = datasets.cifar10.load_data()\n",
    "\n",
    "# 정규화\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "\n",
    "# 부류 벡터를 이진 부류 행렬로 변환\n",
    "y_train = tf.keras.utils.to_categorical(y_train, CLASSES)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), dtype('float64'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 7200)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               3686912   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 3,692,938\n",
      "Trainable params: 3,692,938\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=build((img_rows, img_cols, img_channels), CLASSES)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서보드를 사용하라.\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "313/313 [==============================] - 20s 64ms/step - loss: 1.7006 - accuracy: 0.3972 - val_loss: 1.3622 - val_accuracy: 0.5259\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 20s 64ms/step - loss: 1.3665 - accuracy: 0.5153 - val_loss: 1.2269 - val_accuracy: 0.5776\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 20s 63ms/step - loss: 1.2326 - accuracy: 0.5677 - val_loss: 1.2363 - val_accuracy: 0.5718\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 20s 63ms/step - loss: 1.1483 - accuracy: 0.5990 - val_loss: 1.1925 - val_accuracy: 0.5900\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 20s 64ms/step - loss: 1.0692 - accuracy: 0.6262 - val_loss: 1.1218 - val_accuracy: 0.6137\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 1.0027 - accuracy: 0.6515 - val_loss: 1.0708 - val_accuracy: 0.6342\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 21s 66ms/step - loss: 0.9403 - accuracy: 0.6743 - val_loss: 1.0276 - val_accuracy: 0.6458\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 21s 67ms/step - loss: 0.8946 - accuracy: 0.6869 - val_loss: 1.0383 - val_accuracy: 0.6370\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 21s 66ms/step - loss: 0.8530 - accuracy: 0.7036 - val_loss: 1.0578 - val_accuracy: 0.6472\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 20s 63ms/step - loss: 0.8060 - accuracy: 0.7216 - val_loss: 1.0362 - val_accuracy: 0.6486\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 0.7672 - accuracy: 0.7344 - val_loss: 1.0225 - val_accuracy: 0.6521\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 20s 64ms/step - loss: 0.7357 - accuracy: 0.7453 - val_loss: 1.0292 - val_accuracy: 0.6563\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 21s 67ms/step - loss: 0.7025 - accuracy: 0.7588 - val_loss: 1.0472 - val_accuracy: 0.6572\n",
      "Epoch 14/20\n",
      "313/313 [==============================] - 21s 66ms/step - loss: 0.6740 - accuracy: 0.7672 - val_loss: 1.0682 - val_accuracy: 0.6403\n",
      "Epoch 15/20\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 0.6479 - accuracy: 0.7785 - val_loss: 1.0060 - val_accuracy: 0.6806\n",
      "Epoch 16/20\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 0.6188 - accuracy: 0.7884 - val_loss: 1.0858 - val_accuracy: 0.6529\n",
      "Epoch 17/20\n",
      "313/313 [==============================] - 21s 67ms/step - loss: 0.5928 - accuracy: 0.7972 - val_loss: 1.0777 - val_accuracy: 0.6750\n",
      "Epoch 18/20\n",
      "313/313 [==============================] - 21s 67ms/step - loss: 0.5735 - accuracy: 0.8038 - val_loss: 1.0564 - val_accuracy: 0.6647\n",
      "Epoch 19/20\n",
      "313/313 [==============================] - 21s 67ms/step - loss: 0.5566 - accuracy: 0.8095 - val_loss: 1.0664 - val_accuracy: 0.6759\n",
      "Epoch 20/20\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 0.5363 - accuracy: 0.8199 - val_loss: 1.1481 - val_accuracy: 0.6670\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1517 - accuracy: 0.6631\n",
      "\n",
      "Test score: 1.1516892910003662\n",
      "Test Accuracy: 0.663100004196167\n"
     ]
    }
   ],
   "source": [
    "# 훈련\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIM, metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=BATCH_SIZE,\n",
    "         epochs=EPOCHS, validation_split=VALIDATION_SPLIT,\n",
    "         verbose=VERBOSE, callbacks=callbacks)\n",
    "score = model.evaluate(X_test, y_test,\n",
    "                      batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6009 (pid 59118), started 20:00:52 ago. (Use '!kill 59118' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-363b47145249e194\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-363b47145249e194\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6009;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 심층 신경망으로 CIFAR-10 성능 향상\n",
    "- Conv2D or Convolution2D -> padding='valid' : 입력과 필터가 완전히 겹치는 경우에만 계산, 출력이 입력보다 작음을 의미\n",
    "- Conv2D or Convolution2D -> padding='same' : 출력이 입력과 동일한 크기로 입력 주변 영역에 0이 채워짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, regularizers, optimizers\n",
    "import numpy as np\n",
    "\n",
    "EPOCHS = 50\n",
    "NUM_CLASSES = 10\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "def load_data():\n",
    "    (x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    \n",
    "    # 정규화\n",
    "    mean = np.mean(x_train, axis=(0,1,2,3))\n",
    "    std = np.std(x_train, axis=(0,1,2,3))\n",
    "    x_train = (x_train - mean) / (std + 1e-7)\n",
    "    x_test = (x_test - mean) / (std + 1e-7)\n",
    "    \n",
    "    y_train = tf.keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, NUM_CLASSES)\n",
    "    \n",
    "    return x_train,y_train,x_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), dtype('float32'), (50000, 10), dtype('float32'))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train,y_train,x_test,y_test) = load_data()\n",
    "x_train.shape,x_train.dtype,y_train.shape,y_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 강화\n",
    "def build_model():\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # 첫 번째 블록\n",
    "    model.add(layers.Conv2D(32, (3,3), padding='same',\n",
    "                           input_shape=x_train.shape[1:], activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Conv2D(32, (3,3), padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    \n",
    "    # 두 번째 블록\n",
    "    model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    # 세 번째 블록\n",
    "    model.add(layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(layers.Dropout(0.4))\n",
    "    \n",
    "    # 밀집 출력 계층\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(NUM_CLASSES, activation='softmax'))\n",
    "    # 모델 요약\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 309,290\n",
      "Trainable params: 308,394\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "# 모델 컴파일\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='RMSprop',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서보드를 사용하라.\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "782/782 [==============================] - 149s 191ms/step - loss: 1.7504 - accuracy: 0.4755 - val_loss: 1.4732 - val_accuracy: 0.5798\n",
      "Epoch 2/50\n",
      "782/782 [==============================] - 148s 189ms/step - loss: 1.0791 - accuracy: 0.6529 - val_loss: 1.0840 - val_accuracy: 0.6829\n",
      "Epoch 3/50\n",
      "782/782 [==============================] - 148s 189ms/step - loss: 0.8493 - accuracy: 0.7146 - val_loss: 0.8506 - val_accuracy: 0.7197\n",
      "Epoch 4/50\n",
      "782/782 [==============================] - 147s 189ms/step - loss: 0.7239 - accuracy: 0.7518 - val_loss: 0.7783 - val_accuracy: 0.7441\n",
      "Epoch 5/50\n",
      "782/782 [==============================] - 148s 189ms/step - loss: 0.6461 - accuracy: 0.7775 - val_loss: 0.6709 - val_accuracy: 0.7752\n",
      "Epoch 6/50\n",
      "782/782 [==============================] - 152s 194ms/step - loss: 0.5914 - accuracy: 0.7983 - val_loss: 0.6001 - val_accuracy: 0.7980\n",
      "Epoch 7/50\n",
      "782/782 [==============================] - 151s 193ms/step - loss: 0.5415 - accuracy: 0.8142 - val_loss: 0.5985 - val_accuracy: 0.8058\n",
      "Epoch 8/50\n",
      "782/782 [==============================] - 154s 196ms/step - loss: 0.5089 - accuracy: 0.8251 - val_loss: 0.6024 - val_accuracy: 0.7999\n",
      "Epoch 9/50\n",
      "782/782 [==============================] - 157s 201ms/step - loss: 0.4730 - accuracy: 0.8366 - val_loss: 0.5305 - val_accuracy: 0.8205\n",
      "Epoch 10/50\n",
      "782/782 [==============================] - 157s 201ms/step - loss: 0.4455 - accuracy: 0.8445 - val_loss: 0.5430 - val_accuracy: 0.8182\n",
      "Epoch 11/50\n",
      "782/782 [==============================] - 159s 203ms/step - loss: 0.4260 - accuracy: 0.8503 - val_loss: 0.5772 - val_accuracy: 0.8079\n",
      "Epoch 12/50\n",
      "782/782 [==============================] - 152s 195ms/step - loss: 0.4067 - accuracy: 0.8602 - val_loss: 0.5309 - val_accuracy: 0.8262\n",
      "Epoch 13/50\n",
      "782/782 [==============================] - 158s 203ms/step - loss: 0.3884 - accuracy: 0.8643 - val_loss: 0.5030 - val_accuracy: 0.8336\n",
      "Epoch 14/50\n",
      "782/782 [==============================] - 158s 202ms/step - loss: 0.3706 - accuracy: 0.8694 - val_loss: 0.5179 - val_accuracy: 0.8312\n",
      "Epoch 15/50\n",
      "782/782 [==============================] - 156s 199ms/step - loss: 0.3531 - accuracy: 0.8754 - val_loss: 0.5347 - val_accuracy: 0.8263\n",
      "Epoch 16/50\n",
      "782/782 [==============================] - 150s 192ms/step - loss: 0.3415 - accuracy: 0.8811 - val_loss: 0.5028 - val_accuracy: 0.8361\n",
      "Epoch 17/50\n",
      "782/782 [==============================] - 151s 193ms/step - loss: 0.3243 - accuracy: 0.8847 - val_loss: 0.4959 - val_accuracy: 0.8384\n",
      "Epoch 18/50\n",
      "782/782 [==============================] - 157s 201ms/step - loss: 0.3112 - accuracy: 0.8894 - val_loss: 0.5243 - val_accuracy: 0.8304\n",
      "Epoch 19/50\n",
      "782/782 [==============================] - 158s 202ms/step - loss: 0.3049 - accuracy: 0.8923 - val_loss: 0.4925 - val_accuracy: 0.8466\n",
      "Epoch 20/50\n",
      "782/782 [==============================] - 159s 203ms/step - loss: 0.2956 - accuracy: 0.8957 - val_loss: 0.5092 - val_accuracy: 0.8403\n",
      "Epoch 21/50\n",
      "782/782 [==============================] - 159s 203ms/step - loss: 0.2849 - accuracy: 0.8982 - val_loss: 0.4860 - val_accuracy: 0.8467\n",
      "Epoch 22/50\n",
      "782/782 [==============================] - 160s 204ms/step - loss: 0.2796 - accuracy: 0.8993 - val_loss: 0.4769 - val_accuracy: 0.8496\n",
      "Epoch 23/50\n",
      "782/782 [==============================] - 160s 204ms/step - loss: 0.2668 - accuracy: 0.9048 - val_loss: 0.4837 - val_accuracy: 0.8473\n",
      "Epoch 24/50\n",
      "782/782 [==============================] - 158s 202ms/step - loss: 0.2595 - accuracy: 0.9079 - val_loss: 0.4886 - val_accuracy: 0.8458\n",
      "Epoch 25/50\n",
      "782/782 [==============================] - 151s 193ms/step - loss: 0.2584 - accuracy: 0.9090 - val_loss: 0.4915 - val_accuracy: 0.8463\n",
      "Epoch 26/50\n",
      "782/782 [==============================] - 151s 193ms/step - loss: 0.2425 - accuracy: 0.9145 - val_loss: 0.4598 - val_accuracy: 0.8579\n",
      "Epoch 27/50\n",
      "782/782 [==============================] - 153s 196ms/step - loss: 0.2387 - accuracy: 0.9145 - val_loss: 0.4928 - val_accuracy: 0.8485\n",
      "Epoch 28/50\n",
      "782/782 [==============================] - 154s 197ms/step - loss: 0.2342 - accuracy: 0.9158 - val_loss: 0.4713 - val_accuracy: 0.8562\n",
      "Epoch 29/50\n",
      "782/782 [==============================] - 155s 199ms/step - loss: 0.2289 - accuracy: 0.9186 - val_loss: 0.5042 - val_accuracy: 0.8489\n",
      "Epoch 30/50\n",
      "782/782 [==============================] - 160s 204ms/step - loss: 0.2233 - accuracy: 0.9208 - val_loss: 0.5000 - val_accuracy: 0.8486\n",
      "Epoch 31/50\n",
      "782/782 [==============================] - 159s 204ms/step - loss: 0.2194 - accuracy: 0.9221 - val_loss: 0.5098 - val_accuracy: 0.8467\n",
      "Epoch 32/50\n",
      "782/782 [==============================] - 157s 201ms/step - loss: 0.2187 - accuracy: 0.9213 - val_loss: 0.4696 - val_accuracy: 0.8586\n",
      "Epoch 33/50\n",
      "782/782 [==============================] - 162s 207ms/step - loss: 0.2060 - accuracy: 0.9252 - val_loss: 0.4797 - val_accuracy: 0.8593\n",
      "Epoch 34/50\n",
      "782/782 [==============================] - 163s 209ms/step - loss: 0.2052 - accuracy: 0.9270 - val_loss: 0.4939 - val_accuracy: 0.8554\n",
      "Epoch 35/50\n",
      "782/782 [==============================] - 150s 191ms/step - loss: 0.2081 - accuracy: 0.9271 - val_loss: 0.4701 - val_accuracy: 0.8600\n",
      "Epoch 36/50\n",
      "782/782 [==============================] - 150s 192ms/step - loss: 0.1922 - accuracy: 0.9299 - val_loss: 0.4878 - val_accuracy: 0.8591\n",
      "Epoch 37/50\n",
      "782/782 [==============================] - 150s 192ms/step - loss: 0.1970 - accuracy: 0.9293 - val_loss: 0.4602 - val_accuracy: 0.8627\n",
      "Epoch 38/50\n",
      "782/782 [==============================] - 157s 200ms/step - loss: 0.1920 - accuracy: 0.9302 - val_loss: 0.4884 - val_accuracy: 0.8516\n",
      "Epoch 39/50\n",
      "782/782 [==============================] - 154s 197ms/step - loss: 0.1910 - accuracy: 0.9318 - val_loss: 0.5138 - val_accuracy: 0.8505\n",
      "Epoch 40/50\n",
      "782/782 [==============================] - 160s 204ms/step - loss: 0.1797 - accuracy: 0.9352 - val_loss: 0.5124 - val_accuracy: 0.8548\n",
      "Epoch 41/50\n",
      "782/782 [==============================] - 160s 205ms/step - loss: 0.1798 - accuracy: 0.9349 - val_loss: 0.4878 - val_accuracy: 0.8591\n",
      "Epoch 42/50\n",
      "782/782 [==============================] - 160s 205ms/step - loss: 0.1782 - accuracy: 0.9359 - val_loss: 0.4880 - val_accuracy: 0.8621\n",
      "Epoch 43/50\n",
      "782/782 [==============================] - 161s 205ms/step - loss: 0.1768 - accuracy: 0.9369 - val_loss: 0.5182 - val_accuracy: 0.8517\n",
      "Epoch 44/50\n",
      "782/782 [==============================] - 151s 193ms/step - loss: 0.1730 - accuracy: 0.9372 - val_loss: 0.4778 - val_accuracy: 0.8635\n",
      "Epoch 45/50\n",
      "782/782 [==============================] - 154s 197ms/step - loss: 0.1740 - accuracy: 0.9368 - val_loss: 0.4821 - val_accuracy: 0.8579\n",
      "Epoch 46/50\n",
      "782/782 [==============================] - 160s 204ms/step - loss: 0.1656 - accuracy: 0.9400 - val_loss: 0.4810 - val_accuracy: 0.8582\n",
      "Epoch 47/50\n",
      "782/782 [==============================] - 158s 202ms/step - loss: 0.1678 - accuracy: 0.9394 - val_loss: 0.5066 - val_accuracy: 0.8575\n",
      "Epoch 48/50\n",
      "782/782 [==============================] - 161s 206ms/step - loss: 0.1646 - accuracy: 0.9421 - val_loss: 0.5201 - val_accuracy: 0.8575\n",
      "Epoch 49/50\n",
      "782/782 [==============================] - 165s 211ms/step - loss: 0.1583 - accuracy: 0.9432 - val_loss: 0.5038 - val_accuracy: 0.8582\n",
      "Epoch 50/50\n",
      "782/782 [==============================] - 160s 205ms/step - loss: 0.1632 - accuracy: 0.9416 - val_loss: 0.4918 - val_accuracy: 0.8612\n",
      "79/79 [==============================] - 5s 58ms/step - loss: 0.4918 - accuracy: 0.8612\n",
      "\n",
      "Test score: 0.4917601943016052\n",
      "Test Accuracy: 0.8611999750137329\n"
     ]
    }
   ],
   "source": [
    "# 훈련\n",
    "batch_size = 64\n",
    "model.fit(x_train, y_train, batch_size=batch_size,\n",
    "         epochs=EPOCHS, validation_data=(x_test, y_test),\n",
    "         verbose=1, callbacks=callbacks)\n",
    "score = model.evaluate(x_test, y_test, batch_size=BATCH_SIZE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디스크에 저장\n",
    "model_json = model.to_json()\n",
    "with open('model.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6009 (pid 59118), started 20:00:44 ago. (Use '!kill 59118' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c1727347aefa3e15\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c1727347aefa3e15\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6009;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 보강으로 CIFAR-10 성능 개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# 이미지 보강\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    )\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), dtype('float32'))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습\n",
    "batch_size = 64\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    epochs=EPOCHS,\n",
    "                    verbose=1, validation_data=(x_test,y_test),\n",
    "                   callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디스크에 저장\n",
    "model_json = model.to_json()\n",
    "with open('model.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트\n",
    "scores = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
    "print('\\nTest result: %.3f loss: %.3f' % (scores[1]*100,scores[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR-10 으로 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 309,290\n",
      "Trainable params: 308,394\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras as k\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "\n",
    "from skimage.transform import resize\n",
    "from imageio import imread\n",
    "\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "model = k.models.load_model('model/model_gnr.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imgs.shape: (2, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "img_names = [\"images/cat-standing.jpg\", \"images/dog.jpg\"]\n",
    "imgs = [np.transpose(resize(imread(img_name), (32, 32)), (2, 0, 1)).astype(\"float32\") \n",
    "    for img_name in img_names]\n",
    "#imgs = [resize(imread(img_name), (32, 32)).astype(\"float32\") for img_name in img_names]\n",
    "imgs = np.array(imgs) / 255\n",
    "print(\"imgs.shape:\", imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'optim = SGD()\\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=optim, metrics=[\"accuracy\"])\\n\\npredictions = model.predict(imgs)\\nprint(\"predictions:\", predictions)'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim = SGD()\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optim, metrics=[\"accuracy\"])\n",
    "\n",
    "predictions = model.predict(imgs)\n",
    "print(\"predictions:\", predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
